{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_API_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_API_KEY\"),  \n",
    "  api_version=os.getenv(\"AZURE_API_VERSION\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"GPT-4-32k-playground\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    # stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks=[]\n",
    "for chunk in response:\n",
    "    chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='', choices=[], created=0, model='', object='', system_fingerprint=None, prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n",
      "ChatCompletionChunk(id='chatcmpl-8rRusUcRTib2OTQIZpbzaFU1PnJYX', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=0, id='call_N4RVwuBOh0kma8Ugb3nh7PaV', function=ChoiceDeltaToolCallFunction(arguments='', name='get_current_weather'), type='function')]), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1707749386, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)\n",
      "ChatCompletionChunk(id='chatcmpl-8rRusUcRTib2OTQIZpbzaFU1PnJYX', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='{\\n', name=None), type=None)]), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1707749386, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)\n",
      "ChatCompletionChunk(id='chatcmpl-8rRusUcRTib2OTQIZpbzaFU1PnJYX', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments=' ', name=None), type=None)]), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1707749386, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)\n",
      "ChatCompletionChunk(id='chatcmpl-8rRusUcRTib2OTQIZpbzaFU1PnJYX', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments=' \"', name=None), type=None)]), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1707749386, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)\n",
      "ChatCompletionChunk(id='chatcmpl-8rRusUcRTib2OTQIZpbzaFU1PnJYX', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='location', name=None), type=None)]), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1707749386, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)\n",
      "ChatCompletionChunk(id='chatcmpl-8rRusUcRTib2OTQIZpbzaFU1PnJYX', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='\":', name=None), type=None)]), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1707749386, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)\n",
      "ChatCompletionChunk(id='chatcmpl-8rRusUcRTib2OTQIZpbzaFU1PnJYX', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments=' \"', name=None), type=None)]), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1707749386, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)\n",
      "ChatCompletionChunk(id='chatcmpl-8rRusUcRTib2OTQIZpbzaFU1PnJYX', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='San', name=None), type=None)]), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1707749386, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)\n",
      "ChatCompletionChunk(id='chatcmpl-8rRusUcRTib2OTQIZpbzaFU1PnJYX', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments=' Francisco', name=None), type=None)]), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1707749386, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)\n",
      "ChatCompletionChunk(id='chatcmpl-8rRusUcRTib2OTQIZpbzaFU1PnJYX', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='\"\\n', name=None), type=None)]), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1707749386, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)\n",
      "ChatCompletionChunk(id='chatcmpl-8rRusUcRTib2OTQIZpbzaFU1PnJYX', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='}', name=None), type=None)]), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1707749386, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)\n",
      "ChatCompletionChunk(id='chatcmpl-8rRusUcRTib2OTQIZpbzaFU1PnJYX', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='tool_calls', index=0, logprobs=None, content_filter_results={})], created=1707749386, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)\n"
     ]
    }
   ],
   "source": [
    "chunks=[]\n",
    "for chunk in response:\n",
    "    chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4004616433.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[126], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    elif\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from openai.types.chat import ChatCompletion, ChatCompletionChunk, ChatCompletionMessage, ChatCompletionMessageToolCall\n",
    "from openai.types.chat.chat_completion import Choice\n",
    "from openai.types.chat.chat_completion_message_tool_call import Function\n",
    "\n",
    "if chunks[-1].choices[0].finish_reason == 'tool_calls':\n",
    "    tool_calls=[chunk.choices[0].delta.tool_calls[0] for chunk in chunks[1:-1]]\n",
    "    tool_call_id=tool_calls[0].id\n",
    "    tool_call_name=tool_calls[0].function.name\n",
    "    tool_call_type=tool_calls[0].type\n",
    "    tool_call_arguments=''\n",
    "    for chunk in tool_calls[1:]:\n",
    "        tool_call_arguments+=chunk.function.arguments\n",
    "\n",
    "    ChatCompletion(id=chunks[-1].id, created=chunks[-1].created, model=chunks[-1].model, object='chat.completion', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id=tool_call_id, function=Function(arguments=tool_call_arguments, name=tool_call_name), type=tool_call_type)]))])\n",
    "elif chunks[-1].choices[0].finish_reason == 'stop':\n",
    "    stop_content=''.join(filter(None, [chunk.choices[0].delta.content for chunk in chunks[1:]]))\n",
    "\n",
    "    ChatCompletion(id=chunks[-1].id, created=chunks[-1].created, model=chunks[-1].model, object='chat.completion', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=stop_content, role='assistant', function_call=None, tool_calls=None))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"say hi 3 times\"}]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"GPT-4-32k-playground\",\n",
    "    messages=messages,\n",
    "    # stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for chunk in response:\n",
    "    chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionChunk(id='', choices=[], created=0, model='', object='', system_fingerprint=None, prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]),\n",
       " ChatCompletionChunk(id='chatcmpl-8rSFvkssHVi0y85RsgMqyRQmjsP3I', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1707750691, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None),\n",
       " ChatCompletionChunk(id='chatcmpl-8rSFvkssHVi0y85RsgMqyRQmjsP3I', choices=[Choice(delta=ChoiceDelta(content='Hi', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1707750691, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None),\n",
       " ChatCompletionChunk(id='chatcmpl-8rSFvkssHVi0y85RsgMqyRQmjsP3I', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1707750691, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None),\n",
       " ChatCompletionChunk(id='chatcmpl-8rSFvkssHVi0y85RsgMqyRQmjsP3I', choices=[Choice(delta=ChoiceDelta(content=' hi', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1707750691, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None),\n",
       " ChatCompletionChunk(id='chatcmpl-8rSFvkssHVi0y85RsgMqyRQmjsP3I', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1707750691, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None),\n",
       " ChatCompletionChunk(id='chatcmpl-8rSFvkssHVi0y85RsgMqyRQmjsP3I', choices=[Choice(delta=ChoiceDelta(content=' hi', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1707750691, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None),\n",
       " ChatCompletionChunk(id='chatcmpl-8rSFvkssHVi0y85RsgMqyRQmjsP3I', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1707750691, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None),\n",
       " ChatCompletionChunk(id='chatcmpl-8rSFvkssHVi0y85RsgMqyRQmjsP3I', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None, content_filter_results={})], created=1707750691, model='gpt-4-32k', object='chat.completion.chunk', system_fingerprint=None)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8rSFvkssHVi0y85RsgMqyRQmjsP3I', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hi, hi, hi.', role='assistant', function_call=None, tool_calls=None))], created=1707750691, model='gpt-4-32k', object='chat.completion', system_fingerprint=None, usage=None)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if chunks[-1].choices[0].finish_reason == 'stop':\n",
    "    stop_content=''.join(filter(None, [chunk.choices[0].delta.content for chunk in chunks[1:]]))\n",
    "\n",
    "ChatCompletion(id=chunks[-1].id, created=chunks[-1].created, model=chunks[-1].model, object='chat.completion', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=stop_content, role='assistant', function_call=None, tool_calls=None))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8rSGSf72xDAytYmS2s4O092vOJZ3w', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hi, hi, hi.', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1707750724, model='gpt-4-32k', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=6, prompt_tokens=12, total_tokens=18), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import TypeAdapter\n",
    "from typing import List\n",
    "from openai.types.chat import ChatCompletion, ChatCompletionChunk\n",
    "from openai.types.chat.chat_completion import Choice\n",
    "\n",
    "def merge_chunks_to_completion(chunks: List[ChatCompletionChunk]) -> ChatCompletion:\n",
    "    merged_choices = []\n",
    "    finish_reason = None\n",
    "\n",
    "    new_choice = Choice()\n",
    "    merged_choices.append(new_choice.delta)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        for choice in chunk.choices:\n",
    "            if choice.delta.content is not None:\n",
    "                # If there's content, we're in a streaming scenario\n",
    "                if 'content' not in merged_choices[-1]:\n",
    "                    merged_choices[-1]['content'] = ''\n",
    "                merged_choices[-1]['content'] += choice.delta.content\n",
    "            if choice.delta.tool_calls:\n",
    "                # If there are tool calls, we're in a tool_calls scenario\n",
    "                merged_choices[-1]['tool_calls'] = choice.delta.tool_calls\n",
    "                finish_reason = 'tool_calls'\n",
    "            if choice.finish_reason:\n",
    "                # If there's a finish_reason, it's the end of the stream\n",
    "                finish_reason = choice.finish_reason\n",
    "\n",
    "    # Create the final ChatCompletion object\n",
    "    final_completion = ChatCompletion(\n",
    "        # ... (other fields)\n",
    "        choices=TypeAdapter(List[Choice]).validate_python(merged_choices),\n",
    "        finish_reason=finish_reason\n",
    "    )\n",
    "\n",
    "    return final_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmerge_chunks_to_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 14\u001b[0m, in \u001b[0;36mmerge_chunks_to_completion\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mchoices:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m choice\u001b[38;5;241m.\u001b[39mdelta\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# If there's content, we're in a streaming scenario\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmerged_choices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     15\u001b[0m             merged_choices[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     16\u001b[0m         merged_choices[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m choice\u001b[38;5;241m.\u001b[39mdelta\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "merge_chunks_to_completion(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
