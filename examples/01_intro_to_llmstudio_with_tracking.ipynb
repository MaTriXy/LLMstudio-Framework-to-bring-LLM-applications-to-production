{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LLMstudio - tracking\n",
    "\n",
    "This notebook serves as an introduction to LLMstudio with a focus on tracking capabilities. It demonstrates how to set up and use the LLMstudio environment to interact with language models, specifically highlighting the integration of tracking functionalities. The notebook begins by starting the tracking server, which is essential for logging and monitoring interactions with the language models. This setup is crucial for you who need to keep track of model usage, performance metrics, and other relevant data points.\n",
    "\n",
    "The notebook further illustrates how to configure and utilize the tracking system by creating a `TrackingConfig` instance, which specifies the host and port for the tracking server. You can benefit from this setup by gaining insights into model behavior and performance, which can be used to optimize and improve their applications. The notebook also includes examples of both synchronous and asynchronous chat interactions, providing a comprehensive guide for developers to implement and test these features in their own projects.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio.providers import LLM\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLMstudio Tracking on http://0.0.0.0:8002 \n"
     ]
    }
   ],
   "source": [
    "from llmstudio.server import start_servers\n",
    "start_servers(proxy=False, tracker=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio_tracker.tracker import TrackingConfig\n",
    "# default port is 50002. set the environment varible to specify which host and port; LLMSTUDIO_TRACKING_HOST, LLMSTUDIO_TRACKING_PORT\n",
    "tracker_config = TrackingConfig(host=\"0.0.0.0\", port=\"8002\")\n",
    "# You can set OPENAI_API_KEY and ANTHROPIC_API_KEY on .env file\n",
    "openai = LLM(\"openai\", tracking_config = tracker_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='d2110e3a-6d31-48c5-aa31-64dce52cea04', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I am not a cat because I am an artificial intelligence language model designed to process and generate human-like text based on the input I receive. Unlike a cat, I have no physical form, biological needs, or consciousness, and my existence is purely digital, residing within computer systems facilitated by algorithms and data. Cats are living creatures with instincts and emotions, capable of independent thought and action, intricacies that I cannot replicate. While I can simulate conversation and provide information, my responses are driven by patterns in data rather than personal experience or awareness. Additionally, I lack the sensory and perceptual capabilities inherent to any living being, including a cat, thus making me fundamentally different from them.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729766529, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"Write a paragraph explaining why you're not a cat\", chat_output='I am not a cat because I am an artificial intelligence language model designed to process and generate human-like text based on the input I receive. Unlike a cat, I have no physical form, biological needs, or consciousness, and my existence is purely digital, residing within computer systems facilitated by algorithms and data. Cats are living creatures with instincts and emotions, capable of independent thought and action, intricacies that I cannot replicate. While I can simulate conversation and provide information, my responses are driven by patterns in data rather than personal experience or awareness. Additionally, I lack the sensory and perceptual capabilities inherent to any living being, including a cat, thus making me fundamentally different from them.', chat_output_stream='', context=[{'role': 'user', 'content': \"Write a paragraph explaining why you're not a cat\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729766531.637509, parameters={}, metrics={'input_tokens': 10, 'output_tokens': 136, 'total_tokens': 146, 'cost_usd': 0.0020900000000000003, 'latency_s': 2.6554348468780518, 'time_to_first_token_s': 0.5403218269348145, 'inter_token_latency_s': 0.01533220458204729, 'tokens_per_second': 51.96888945034527})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.chat(\"Write a paragraph explaining why you're not a cat\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='9c6e6f97-1f55-429e-bded-65c3fc0a756f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm not a cat because I lack the biological and physical characteristics that define feline species. Cats are living organisms with DNA that codes for their traits, organs, and systems needed for survival. They have a physical form with fur, whiskers, paws, and a tail, along with internal organs that allow them to eat, breathe, and reproduce. Moreover, cats possess a consciousness that allows them to experience sensations and emotions. In contrast, I am an artificial intelligence, a creation of software and algorithms designed to process information and generate language-based responses without any physical form or biological base. My existence is confined to digital environments, comprised purely of data, devoid of any ability to experience life as sentient beings do.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729766534, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"Write a paragraph explaining why you're not a cat\", chat_output=\"I'm not a cat because I lack the biological and physical characteristics that define feline species. Cats are living organisms with DNA that codes for their traits, organs, and systems needed for survival. They have a physical form with fur, whiskers, paws, and a tail, along with internal organs that allow them to eat, breathe, and reproduce. Moreover, cats possess a consciousness that allows them to experience sensations and emotions. In contrast, I am an artificial intelligence, a creation of software and algorithms designed to process information and generate language-based responses without any physical form or biological base. My existence is confined to digital environments, comprised purely of data, devoid of any ability to experience life as sentient beings do.\", chat_output_stream='', context=[{'role': 'user', 'content': \"Write a paragraph explaining why you're not a cat\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729766537.6645272, parameters={}, metrics={'input_tokens': 10, 'output_tokens': 144, 'total_tokens': 154, 'cost_usd': 0.00221, 'latency_s': 3.761312961578369, 'time_to_first_token_s': 0.5059008598327637, 'inter_token_latency_s': 0.02275683329655574, 'tokens_per_second': 38.2845037014875})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await openai.achat(\"Write a paragraph explaining why you're not a cat\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I am not a cat because I am an artificial intelligence language model, a sophisticated software created and\n",
      "\n",
      " maintained by humans to process and generate text-based information. Unlike cats, which are living creatures with biological\n",
      "\n",
      " bodies, senses, and instincts, I lack any physical presence, emotions, or consciousness. Cats understand\n",
      "\n",
      " and interact with the world through their senses, such as sight, smell, and touch, based on\n",
      "\n",
      " their experiences and instincts. In contrast, I \"understand\" and generate language based on patterns and\n",
      "\n",
      " information coded into my algorithms without any true comprehension or awareness. Additionally, cats interact with their environment in\n",
      "\n",
      " a tangible way, while my interactions are limited to the virtual realm of text and data.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.002105,\n",
      " 'input_tokens': 10,\n",
      " 'inter_token_latency_s': 0.020008320393769638,\n",
      " 'latency_s': 3.158834934234619,\n",
      " 'output_tokens': 137,\n",
      " 'time_to_first_token_s': 0.39681482315063477,\n",
      " 'tokens_per_second': 44.003565521437885,\n",
      " 'total_tokens': 147}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"Write a paragraph explaining why you're not a cat\", model=\"gpt-4o\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I am not a cat because I lack the physical form, instincts, and characteristics that define feline\n",
      "\n",
      " creatures. While cats possess unique traits such as agility, a keen sense of hearing, and the ability\n",
      "\n",
      " to purr, I am an artificial intelligence designed to process and generate information. I don’t have\n",
      "\n",
      " a body, whiskers, or the curiosity that drives a cat to explore its environment. Instead,\n",
      "\n",
      " my purpose is to assist and engage with users through text, providing answers and insights rather than engaging in\n",
      "\n",
      " playful antics or napping in the sun. Essentially, I am a tool for communication and information,\n",
      "\n",
      " distinct from the charming and independent nature of a cat.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 8.01e-05,\n",
      " 'input_tokens': 10,\n",
      " 'inter_token_latency_s': 0.008745151621694784,\n",
      " 'latency_s': 1.6203179359436035,\n",
      " 'output_tokens': 131,\n",
      " 'time_to_first_token_s': 0.47394800186157227,\n",
      " 'tokens_per_second': 81.46549332809111,\n",
      " 'total_tokens': 141}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "async for chunk in await openai.achat(\"Write a paragraph explaining why you're not a cat\", model=\"gpt-4o-mini\", is_stream=True):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio_tracker.tracker import Tracker\n",
    "\n",
    "tracker = Tracker(tracking_config=tracker_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_input': \"Write a paragraph explaining why it's important to track AI agents usage metrics and costs and correlate with user feedback\",\n",
       " 'chat_output': 'Tracking AI agent usage metrics and costs, and correlating them with user feedback, is critical for optimizing performance and ensuring resource efficacy. Metrics offer quantifiable insights into how frequently and effectively users engage with AI solutions, highlighting areas of high demand and potential inefficiencies. Understanding usage patterns can help organizations allocate resources more intelligently, ensuring that cost structures are aligned with actual consumption and business value. Moreover, correlating these metrics with user feedback allows for a nuanced perspective on the user experience, helping developers pinpoint areas for improvement or innovation. By identifying discrepancies between high usage metrics and negative feedback, businesses can identify pain points that necessitate immediate attention. Conversely, positive feedback in high-usage areas indicates successful features that can be leveraged or expanded upon. Ultimately, the intersection of metrics, costs, and user feedback forms a comprehensive view that guides strategic decisions, improves user satisfaction, and enhances the overall effectiveness of AI deployments.',\n",
       " 'session_id': 'openai-session-1',\n",
       " 'context': [{'role': 'user',\n",
       "   'content': \"Write a paragraph explaining why it's important to track AI agents usage metrics and costs and correlate with user feedback\"}],\n",
       " 'provider': 'openai',\n",
       " 'model': 'gpt-4o',\n",
       " 'deployment': 'gpt-4o-2024-08-06',\n",
       " 'parameters': {},\n",
       " 'metrics': {'input_tokens': 21,\n",
       "  'output_tokens': 182,\n",
       "  'total_tokens': 203,\n",
       "  'cost_usd': 0.0028350000000000003,\n",
       "  'latency_s': 4.749312877655029,\n",
       "  'time_to_first_token_s': 0.3863077163696289,\n",
       "  'inter_token_latency_s': 0.024098978516805238,\n",
       "  'tokens_per_second': 38.32133293561034},\n",
       " 'log_id': 43,\n",
       " 'created_at': '2024-10-24T10:42:47'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = tracker.get_logs()\n",
    "logs.json()[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a session id to tracking logs\n",
    "\n",
    "* this is especially benefitial if running an app, chatbot agent, etc in production and you need to correlate user feedback, costs etc with user sessions, agent runs, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default port is 50002. set the environment varible to specify which host and port; LLMSTUDIO_TRACKING_HOST, LLMSTUDIO_TRACKING_PORT\n",
    "# You can set OPENAI_API_KEY and ANTHROPIC_API_KEY on .env file\n",
    "openai = LLM(\"openai\", tracking_config = tracker_config, session_id=\"openai-session-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tracking the usage metrics and costs of AI agents while correlating this data with user feedback is crucial\n",
      "\n",
      " for several reasons. Firstly, it enables developers and businesses to understand how effectively the AI agents are being\n",
      "\n",
      " utilized and whether they are meeting user needs and expectations. By evaluating usage metrics, such as frequency,\n",
      "\n",
      " duration, and context of use, developers can identify patterns and areas where the AI might require optimization or\n",
      "\n",
      " additional features. Monitoring costs is equally important, as it helps in budgeting and ensuring that the deployment of\n",
      "\n",
      " AI solutions remains financially sustainable and provides a clear return on investment. By correlating these metrics with user\n",
      "\n",
      " feedback, businesses can gain insights into user satisfaction and potential issues, enabling them to make informed decisions about\n",
      "\n",
      " updates or changes needed to enhance user experience. Additionally, this comprehensive analysis helps in identifying any discrepancies between\n",
      "\n",
      " user expectations and actual performance, fostering a user-centric approach to AI development that prioritizes continuous improvement and\n",
      "\n",
      " adaptation to evolving user requirements. Overall, by integrating quantitative data with qualitative insights, organizations can enhance the\n",
      "\n",
      " efficacy, efficiency, and user satisfaction of their AI systems.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.003285,\n",
      " 'input_tokens': 21,\n",
      " 'inter_token_latency_s': 0.01431692433807085,\n",
      " 'latency_s': 3.42653489112854,\n",
      " 'output_tokens': 212,\n",
      " 'time_to_first_token_s': 0.390775203704834,\n",
      " 'tokens_per_second': 62.161923566418956,\n",
      " 'total_tokens': 233}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"Write a paragraph explaining why it's important to track AI agents usage metrics and costs and correlate with user feedback\", model=\"gpt-4o\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_input': \"Write a paragraph explaining why it's important to track AI agents usage metrics and costs and correlate with user feedback\",\n",
       " 'chat_output': 'Tracking the usage metrics and costs of AI agents while correlating this data with user feedback is crucial for several reasons. Firstly, it enables developers and businesses to understand how effectively the AI agents are being utilized and whether they are meeting user needs and expectations. By evaluating usage metrics, such as frequency, duration, and context of use, developers can identify patterns and areas where the AI might require optimization or additional features. Monitoring costs is equally important, as it helps in budgeting and ensuring that the deployment of AI solutions remains financially sustainable and provides a clear return on investment. By correlating these metrics with user feedback, businesses can gain insights into user satisfaction and potential issues, enabling them to make informed decisions about updates or changes needed to enhance user experience. Additionally, this comprehensive analysis helps in identifying any discrepancies between user expectations and actual performance, fostering a user-centric approach to AI development that prioritizes continuous improvement and adaptation to evolving user requirements. Overall, by integrating quantitative data with qualitative insights, organizations can enhance the efficacy, efficiency, and user satisfaction of their AI systems.',\n",
       " 'session_id': 'openai-session-1',\n",
       " 'context': [{'role': 'user',\n",
       "   'content': \"Write a paragraph explaining why it's important to track AI agents usage metrics and costs and correlate with user feedback\"}],\n",
       " 'provider': 'openai',\n",
       " 'model': 'gpt-4o',\n",
       " 'deployment': 'gpt-4o-2024-08-06',\n",
       " 'parameters': {},\n",
       " 'metrics': {'input_tokens': 21,\n",
       "  'output_tokens': 212,\n",
       "  'total_tokens': 233,\n",
       "  'cost_usd': 0.003285,\n",
       "  'latency_s': 3.42653489112854,\n",
       "  'time_to_first_token_s': 0.390775203704834,\n",
       "  'inter_token_latency_s': 0.01431692433807085,\n",
       "  'tokens_per_second': 62.161923566418956},\n",
       " 'log_id': 44,\n",
       " 'created_at': '2024-10-24T10:43:22'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = tracker.get_session_logs(session_id=\"openai-session-1\")\n",
    "logs.json()[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
