{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.schema import LLMResult\n",
    "\n",
    "class MyCustomHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token:str, **kwargs) -> None:\n",
    "        print(f\"Received streaming token {token}, kwargs:{kwargs}\")\n",
    "        \n",
    "    def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n",
    "        print(f\"Received non-streaming response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain.schema.messages import BaseMessage, AIMessage, HumanMessage\n",
    "from langchain.schema.output import ChatResult, ChatGeneration\n",
    "from langchain_core.callbacks import Callbacks\n",
    "from llmstudio.llm import LLM\n",
    "from typing import Any, Optional\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "class ChatLLMstudio(ChatOpenAI):\n",
    "    model_id: str\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        return \"LLMstudio\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        **kwargs\n",
    "    ) -> str:\n",
    "        print(\"_CALL\")\n",
    "        llm = LLM(self.model_id)\n",
    "        response = llm.chat(prompt, **kwargs)\n",
    "        return response.get('chat_output', '')\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        callbacks: Callbacks = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> BaseMessage:\n",
    "        print(\"CALL\")\n",
    "        print({**kwargs})\n",
    "        input_text = self._convert_messages_to_text(messages)\n",
    "        llm = LLM(self.model_id)\n",
    "        response = llm.chat(input_text, **kwargs)\n",
    "        return AIMessage(content=response.get('chat_output', ''))\n",
    "\n",
    "    async def _call_async(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        callbacks: Callbacks = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> BaseMessage:\n",
    "        print(\"CALL ASYNC\")\n",
    "        input_text = self._convert_messages_to_text(messages)\n",
    "        llm = LLM(self.model_id)\n",
    "        response = await llm.async_chat(input_text, **kwargs)\n",
    "        return AIMessage(content=response.get('chat_output', ''))\n",
    "\n",
    "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
    "        print(\"GENERATE\")\n",
    "        input_text = self._convert_messages_to_text(messages)\n",
    "        llm = LLM(self.model_id)\n",
    "        response = llm.chat(input_text, **kwargs)\n",
    "        return self._convert_response_to_chat_result(response)\n",
    "\n",
    "    async def _agenerate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
    "        print(\"AGENERATE\")\n",
    "        input_text = self._convert_messages_to_text(messages)\n",
    "        llm = LLM(self.model_id)\n",
    "        response = await llm.async_chat(input_text, **kwargs)\n",
    "        return self._convert_response_to_chat_result(response)\n",
    "\n",
    "    def _stream(self, messages: List[BaseMessage], **kwargs):\n",
    "        input_text = self._convert_messages_to_text(messages)\n",
    "        llm = LLM(self.model_id)\n",
    "        for chunk in llm.chat(input_text, is_stream=True, **kwargs):\n",
    "            yield chunk\n",
    "\n",
    "    async def _astream(self, messages: List[BaseMessage], **kwargs):\n",
    "        input_text = self._convert_messages_to_text(messages)\n",
    "        llm = LLM(self.model_id)\n",
    "        async for chunk in await llm.async_chat(input_text, is_stream=True, **kwargs):\n",
    "            yield chunk\n",
    "\n",
    "    def _convert_messages_to_text(self, messages: List[BaseMessage]) -> str:\n",
    "        return \" \".join([message.content for message in messages if isinstance(message, HumanMessage)])\n",
    "\n",
    "    def _convert_response_to_chat_result(self, response) -> ChatResult:\n",
    "        chat_output = response.get('chat_output', '')\n",
    "        return ChatResult(generations=[ChatGeneration(message=AIMessage(content=chat_output))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt3 = ChatLLMstudio(model_id='openai/gpt-3.5-turbo', callbacks=[MyCustomHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "\n",
    "@tool\n",
    "def get_departure(ticket_number: str):\n",
    "    \"\"\"Use this to fetch the departure time of a train\"\"\"\n",
    "    return \"12:00 AM\"\n",
    "\n",
    "@tool\n",
    "def cancel_ticket(ticket_number: str):\n",
    "    \"\"\"Use this to cancel a ticket\"\"\"\n",
    "    return \"Ticket cancelled\"\n",
    "\n",
    "@tool\n",
    "def buy_ticket(destination: str):\n",
    "    \"\"\"Use this to buy a ticket\"\"\"\n",
    "    return \"Bought ticket number 123456\"\n",
    "\n",
    "@tool\n",
    "def make_complaint(complaint: str):\n",
    "    \"\"\"Use this to forward a complaint to the complaint department\"\"\"\n",
    "    return \"Complaint forwarded. We appreciate your feedback.\"\n",
    "\n",
    "\n",
    "def assistant(question: str)->str:\n",
    "    \"\"\"YOUR CODE HERE\"\"\"\n",
    "    tools = [get_departure, cancel_ticket, buy_ticket, make_complaint]\n",
    "\n",
    "    #rebuild agent with new tools\n",
    "    agent_executor = initialize_agent(\n",
    "        tools, gpt3, agent=AgentType.OPENAI_MULTI_FUNCTIONS, handle_parsing_errors=\"Check your output and make sure it conforms!\", verbose = True, debug = True\n",
    "    )\n",
    "\n",
    "    response = agent_executor.invoke(\n",
    "        {\n",
    "            \"input\": question\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "CALL\n",
      "{'functions': [{'name': 'tool_selection', 'description': 'A list of actions to take.', 'parameters': {'title': 'tool_selection', 'description': 'A list of actions to take.', 'type': 'object', 'properties': {'actions': {'title': 'actions', 'type': 'array', 'items': {'title': 'tool_call', 'type': 'object', 'properties': {'action_name': {'title': 'action_name', 'enum': ['get_departure', 'cancel_ticket', 'buy_ticket', 'make_complaint'], 'type': 'string', 'description': 'Name of the action to take. The name provided here should match up with the parameters for the action below.'}, 'action': {'title': 'Action', 'anyOf': [{'title': 'get_departure', 'type': 'object', 'properties': {'ticket_number': {'title': 'Ticket Number', 'type': 'string'}}}, {'title': 'cancel_ticket', 'type': 'object', 'properties': {'ticket_number': {'title': 'Ticket Number', 'type': 'string'}}}, {'title': 'buy_ticket', 'type': 'object', 'properties': {'destination': {'title': 'Destination', 'type': 'string'}}}, {'title': 'make_complaint', 'type': 'object', 'properties': {'complaint': {'title': 'Complaint', 'type': 'string'}}}]}}, 'required': ['action_name', 'action']}}}, 'required': ['actions']}}]}\n",
      "Chatting with openai/gpt-3.5-turbo\n",
      "{'functions': [{'name': 'tool_selection', 'description': 'A list of actions to take.', 'parameters': {'title': 'tool_selection', 'description': 'A list of actions to take.', 'type': 'object', 'properties': {'actions': {'title': 'actions', 'type': 'array', 'items': {'title': 'tool_call', 'type': 'object', 'properties': {'action_name': {'title': 'action_name', 'enum': ['get_departure', 'cancel_ticket', 'buy_ticket', 'make_complaint'], 'type': 'string', 'description': 'Name of the action to take. The name provided here should match up with the parameters for the action below.'}, 'action': {'title': 'Action', 'anyOf': [{'title': 'get_departure', 'type': 'object', 'properties': {'ticket_number': {'title': 'Ticket Number', 'type': 'string'}}}, {'title': 'cancel_ticket', 'type': 'object', 'properties': {'ticket_number': {'title': 'Ticket Number', 'type': 'string'}}}, {'title': 'buy_ticket', 'type': 'object', 'properties': {'destination': {'title': 'Destination', 'type': 'string'}}}, {'title': 'make_complaint', 'type': 'object', 'properties': {'complaint': {'title': 'Complaint', 'type': 'string'}}}]}}, 'required': ['action_name', 'action']}}}, 'required': ['actions']}}]}\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"action_name\": \"get_departure\",\n",
      "      \"action\": {\n",
      "        \"ticket_number\": \"1234\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'When does my train depart? My ticket number is 1234',\n",
       " 'output': '{\\n  \"actions\": [\\n    {\\n      \"action_name\": \"get_departure\",\\n      \"action\": {\\n        \"ticket_number\": \"1234\"\\n      }\\n    }\\n  ]\\n}'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant('When does my train depart? My ticket number is 1234')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = client.chat.completions.create(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=[{\"role\": \"user\", \"content\": 'When does my train depart? My ticket number is 1234'}],\n",
    "#     function_call=\"auto\",\n",
    "#     functions=[{'name': 'tool_selection', 'description': 'A list of actions to take.', 'parameters': {'title': 'tool_selection', 'description': 'A list of actions to take.', 'type': 'object', 'properties': {'actions': {'title': 'actions', 'type': 'array', 'items': {'title': 'tool_call', 'type': 'object', 'properties': {'action_name': {'title': 'action_name', 'enum': ['get_departure', 'cancel_ticket', 'buy_ticket', 'make_complaint'], 'type': 'string', 'description': 'Name of the action to take. The name provided here should match up with the parameters for the action below.'}, 'action': {'title': 'Action', 'anyOf': [{'title': 'get_departure', 'type': 'object', 'properties': {'ticket_number': {'title': 'Ticket Number', 'type': 'string'}}}, {'title': 'cancel_ticket', 'type': 'object', 'properties': {'ticket_number': {'title': 'Ticket Number', 'type': 'string'}}}, {'title': 'buy_ticket', 'type': 'object', 'properties': {'destination': {'title': 'Destination', 'type': 'string'}}}, {'title': 'make_complaint', 'type': 'object', 'properties': {'complaint': {'title': 'Complaint', 'type': 'string'}}}]}}, 'required': ['action_name', 'action']}}}, 'required': ['actions']}}],\n",
    "#     stream=True\n",
    "#     )\n",
    "\n",
    "# for chunk in response:\n",
    "#     print(chunk.choices[0].delta.function_call.arguments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresponse\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "for chunk in response:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/kbcv02t933zfz4yczvfqcqvw0000gn/T/ipykernel_31096/1974112764.py:2: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response.choices[0].message.function_call.dict()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'arguments': '{\\n  \"actions\": [\\n    {\\n      \"action_name\": \"get_departure\",\\n      \"action\": {\\n        \"ticket_number\": \"1234\"\\n      }\\n    }\\n  ]\\n}',\n",
       " 'name': 'tool_selection'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "response.choices[0].message.function_call.dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
