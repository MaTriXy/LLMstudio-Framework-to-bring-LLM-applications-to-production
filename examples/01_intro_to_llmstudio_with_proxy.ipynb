{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LLMstudio - proxy\n",
    "\n",
    "This tutorial serves as an introduction to LLMstudio, a platform designed to facilitate interactions with large language models (LLMs) through a proxy server. By following this guide, users will learn how to set up and run a proxy server that acts as an intermediary between the client and the LLM provider, ensuring seamless communication and data handling. The notebook demonstrates the process of initializing the server, configuring the proxy, and making requests to the LLM, providing a comprehensive overview of the system's capabilities.\n",
    "\n",
    "Additionally, the tutorial highlights the integration of tracking features within LLMstudio, allowing users to monitor and log interactions with the LLMs. This is particularly useful for analyzing performance metrics, such as latency and token usage, which can help in optimizing the model's responses and understanding its behavior in different scenarios. By the end of this tutorial, users will have a solid foundation in setting up and utilizing LLMstudio for efficient and effective LLM interactions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start proxy server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLMstudio Proxy on http://0.0.0.0:8001 \n",
      "Running LLMstudio Tracking on http://0.0.0.0:8002 \n"
     ]
    }
   ],
   "source": [
    "from llmstudio.server import start_servers\n",
    "start_servers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to LLMStudio Proxy @ 0.0.0.0:8001\n"
     ]
    }
   ],
   "source": [
    "from llmstudio_proxy.provider import LLMProxyProvider as LLM\n",
    "from llmstudio_proxy.provider import ProxyConfig\n",
    "\n",
    "llm = LLM(provider=\"openai\", \n",
    "          proxy_config=ProxyConfig(host=\"0.0.0.0\", port=\"8001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.chat(\"olá\", model=\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Olá! Como posso ajudar você hoje?',\n",
       " {'input_tokens': 2,\n",
       "  'output_tokens': 11,\n",
       "  'total_tokens': 13,\n",
       "  'cost_usd': 0.000175,\n",
       "  'latency_s': 1.154630184173584,\n",
       "  'time_to_first_token_s': 1.0609641075134277,\n",
       "  'inter_token_latency_s': 0.00980022218492296,\n",
       "  'tokens_per_second': 8.66078172653819})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.chat_output, result.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the LLMStudio sdk entrypoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio.providers import LLM\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host='0.0.0.0' port='8001' url=None username=None password=None\n",
      "Connected to LLMStudio Proxy @ 0.0.0.0:8001\n"
     ]
    }
   ],
   "source": [
    "# You can set OPENAI_API_KEY and ANTHROPIC_API_KEY on .env file\n",
    "from llmstudio_proxy.provider import ProxyConfig\n",
    "proxy = ProxyConfig(host=\"0.0.0.0\", port=\"8001\")\n",
    "print(proxy)\n",
    "\n",
    "openai = LLM(\"openai\", proxy_config=proxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llmstudio_proxy.provider.LLMProxyProvider at 0x10a976900>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai._provider\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='fde9001a-c9fb-4a52-b23e-a3002d53a3c0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I’m called ChatGPT. How can I assist you today?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729178752, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output='I’m called ChatGPT. How can I assist you today?', chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729178753.123771, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 14, 'total_tokens': 18, 'cost_usd': 0.00023, 'latency_s': 0.8865439891815186, 'time_to_first_token_s': 0.7208070755004883, 'inter_token_latency_s': 0.011822138513837541, 'tokens_per_second': 16.919634200947442})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.chat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "await openai.achat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, the vast and enigmatic expanse that stretches beyond our planet, has captivated human imagination for\n",
      "\n",
      " centuries. It is a boundless arena, filled with billions of galaxies, each containing countless stars and\n",
      "\n",
      " planets, many still shrouded in mystery. The infinite darkness of space is punctuated by the\n",
      "\n",
      " brilliant glow of stars and the swirling colors of nebulae, painting a picture of both incredible beauty\n",
      "\n",
      " and monumental scale. As humanity ventures further into this final frontier, fueled by advances in technology and a\n",
      "\n",
      " relentless curiosity, we aim to uncover the secrets of distant worlds, understand the fundamental forces that govern the\n",
      "\n",
      " universe, and perhaps find signs of life beyond Earth. Space exploration challenges us to push beyond our limits\n",
      "\n",
      ", fostering innovation and cooperation on a global scale, and inspiring generations to look up and dream of what\n",
      "\n",
      " lies beyond our sky.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.00253,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.01107682314786044,\n",
      " 'latency_s': 2.4938130378723145,\n",
      " 'output_tokens': 166,\n",
      " 'time_to_first_token_s': 0.6631622314453125,\n",
      " 'tokens_per_second': 66.56473339381881,\n",
      " 'total_tokens': 174}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"Write a paragfraph about space\", model=\"gpt-4o\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, the vast expanse beyond Earth's atmosphere, captivates the imagination and science alike with its\n",
      "\n",
      " boundless mysteries and breathtaking beauty. It is a realm of solitude and silence, where distant stars burn\n",
      "\n",
      " like ancient beacons of light and galaxies spiral gracefully across the cosmos. The vastness of space is\n",
      "\n",
      " not just about distance; it's also a window into time, as the light from celestial objects takes millions\n",
      "\n",
      ", sometimes billions, of years to reach us, allowing astronomers to glimpse the universe's history.\n",
      "\n",
      " From the swirling clouds of nebulae to the enigmatic pull of black holes, space is a dynamic\n",
      "\n",
      " playground of physical laws that govern the existence of everything we know. As we continue to explore this celestial\n",
      "\n",
      " frontier, each new discovery deepens our understanding of the universe and our place within it, fostering a\n",
      "\n",
      " sense of wonder that inspires generations to reach for the stars.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.00010559999999999999,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.01177175100459609,\n",
      " 'latency_s': 3.162630081176758,\n",
      " 'output_tokens': 174,\n",
      " 'time_to_first_token_s': 1.137415885925293,\n",
      " 'tokens_per_second': 54.70130731686135,\n",
      " 'total_tokens': 182}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "async for chunk in await openai.achat(\"Write a paragfraph about space\", model=\"gpt-4o-mini\", is_stream=True):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
