{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LLMstudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start proxy server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLMstudio Proxy on http://0.0.0.0:8001 \n",
      "Running LLMstudio Tracking on http://0.0.0.0:8002 \n"
     ]
    }
   ],
   "source": [
    "from llmstudio.server import start_servers\n",
    "start_servers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to LLMStudio Proxy @ 0.0.0.0:8001\n"
     ]
    }
   ],
   "source": [
    "from llmstudio_proxy.provider import LLMProxyProvider as LLM\n",
    "from llmstudio_proxy.provider import ProxyConfig\n",
    "\n",
    "llm = LLM(provider=\"openai\", \n",
    "          proxy_config=ProxyConfig(host=\"0.0.0.0\", port=\"8001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.chat(\"olá\", model=\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Olá! Como posso ajudá-lo hoje?',\n",
       " {'input_tokens': 2,\n",
       "  'output_tokens': 11,\n",
       "  'total_tokens': 13,\n",
       "  'cost_usd': 0.000175,\n",
       "  'latency_s': 0.9982657432556152,\n",
       "  'time_to_first_token_s': 0.8587729930877686,\n",
       "  'inter_token_latency_s': 0.01456777254740397,\n",
       "  'tokens_per_second': 10.01737269615933})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.chat_output, result.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio import LLM\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host='0.0.0.0' port='8001' url=None username=None password=None\n",
      "Connected to LLMStudio Proxy @ 0.0.0.0:8001\n"
     ]
    }
   ],
   "source": [
    "# You can set OPENAI_API_KEY and ANTHROPIC_API_KEY on .env file\n",
    "from llmstudio_proxy.provider import ProxyConfig\n",
    "proxy = ProxyConfig(host=\"0.0.0.0\", port=\"8001\")\n",
    "print(proxy)\n",
    "\n",
    "openai = LLM(\"openai\", proxy_config=proxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llmstudio_proxy.provider.LLMProxyProvider at 0x10cf8c680>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai._provider\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='dc5d3ebe-31a1-4f86-ab37-74ef17740be2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I don't have a personal name, but you can call me Assistant. How can I help you today?\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729091060, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output=\"I don't have a personal name, but you can call me Assistant. How can I help you today?\", chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729091060.91643, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 22, 'total_tokens': 26, 'cost_usd': 0.00035, 'latency_s': 0.7695848941802979, 'time_to_first_token_s': 0.5569219589233398, 'inter_token_latency_s': 0.009642221710898659, 'tokens_per_second': 29.886241497109708})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.chat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='2ae2738f-deb9-48dd-af77-590570029ba4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I don't have a personal name, but you can call me Assistant! How can I assist you today?\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729091063, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output=\"I don't have a personal name, but you can call me Assistant! How can I assist you today?\", chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729091064.392381, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 22, 'total_tokens': 26, 'cost_usd': 0.00035, 'latency_s': 1.7545521259307861, 'time_to_first_token_s': 0.8596808910369873, 'inter_token_latency_s': 0.040647235783663666, 'tokens_per_second': 13.10875844614679})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await openai.achat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, an infinite expanse that stretches beyond the confines of our planet, is a vast and\n",
      "\n",
      " mysterious frontier that has fascinated humanity for centuries. It is a realm where stars twinkle and galaxies swirl\n",
      "\n",
      ", each a cosmic masterpiece, and where the laws of physics often defy our earthly understanding. Exploration\n",
      "\n",
      " of this enigmatic domain has led to remarkable scientific discoveries and technological advancements, from the moon landings to\n",
      "\n",
      " the deployment of telescopes that peer into the furthest reaches of the universe. Space is not only\n",
      "\n",
      " the home of planets and celestial bodies but also a crucible for the fundamental questions of existence, challenging\n",
      "\n",
      " us to ponder our place in the cosmos. The vastness of space, with its myriad wonders and\n",
      "\n",
      " potential for future exploration, continues to inspire awe and drive the quest for knowledge, pushing the boundaries of\n",
      "\n",
      " what we know and inviting us to explore the unknown.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.0025900000000000003,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.02241540373417369,\n",
      " 'latency_s': 4.408563852310181,\n",
      " 'output_tokens': 170,\n",
      " 'time_to_first_token_s': 0.574927806854248,\n",
      " 'tokens_per_second': 39.01497307561245,\n",
      " 'total_tokens': 178}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"Write a paragfraph about space\", model=\"gpt-4o\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, the vast and enigmatic expanse beyond our planet, captivates the imagination of humanity with\n",
      "\n",
      " its infinite possibilities and mysteries. Stretching billions of light-years, it is the realm where galaxies dance\n",
      "\n",
      ", stars are born, and black holes lurk, challenging our understanding of the universe. The vacuum\n",
      "\n",
      " of space, nearly devoid of matter, creates a backdrop for celestial phenomena that evoke wonder and curiosity.\n",
      "\n",
      " From the swirling arms of spiral galaxies to the delicate hues of nebulae, space is a canvas\n",
      "\n",
      " of extraordinary beauty shaped over billions of years. As we venture further into this cosmic frontier with advanced technology\n",
      "\n",
      ", we unearth clues about the origins of the universe, the potential for extraterrestrial life, and\n",
      "\n",
      " the fundamental laws that govern existence itself, reminding us of our small yet significant place in the cosmos.\n",
      "\n",
      "\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 9.779999999999999e-05,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.08299692422151565,\n",
      " 'latency_s': 13.905935049057007,\n",
      " 'output_tokens': 161,\n",
      " 'time_to_first_token_s': 0.6256401538848877,\n",
      " 'tokens_per_second': 11.577790305508278,\n",
      " 'total_tokens': 169}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "async for chunk in await openai.achat(\"Write a paragfraph about space\", model=\"gpt-4o-mini\", is_stream=True):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
