{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LLMstudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start proxy server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLMstudio Engine on http://0.0.0.0:8001 \n",
      "Running LLMstudio Tracking on http://0.0.0.0:8002 \n"
     ]
    }
   ],
   "source": [
    "from llmstudio.server import start_server\n",
    "start_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to LLMStudio Proxy @ 0.0.0.0:8001\n"
     ]
    }
   ],
   "source": [
    "from llmstudio.engine.provider import LLMProxyProvider as LLM\n",
    "from llmstudio.engine.provider import ProxyConfig\n",
    "\n",
    "# from llmstudio_core import LLMCore as LLM\n",
    "# from llmstudio import LLM\n",
    "\n",
    "llm = LLM(provider=\"openai\", \n",
    "          proxy_config=ProxyConfig(host=\"0.0.0.0\", port=\"8001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.chat(\"olá\", model=\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Olá! Como posso ajudar você hoje?',\n",
       " {'input_tokens': 2,\n",
       "  'output_tokens': 11,\n",
       "  'total_tokens': 13,\n",
       "  'cost_usd': 0.000175,\n",
       "  'latency_s': 0.6496210098266602,\n",
       "  'time_to_first_token_s': 0.5341501235961914,\n",
       "  'inter_token_latency_s': 0.01241710450914171,\n",
       "  'tokens_per_second': 15.393590799454474})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.chat_output, result.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio import LLM\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host='0.0.0.0' port='8001' url=None username=None password=None\n",
      "Connected to LLMStudio Proxy @ 0.0.0.0:8001\n"
     ]
    }
   ],
   "source": [
    "# You can set OPENAI_API_KEY and ANTHROPIC_API_KEY on .env file\n",
    "from llmstudio.engine.provider import ProxyConfig\n",
    "proxy = ProxyConfig(host=\"0.0.0.0\", port=\"8001\")\n",
    "print(proxy)\n",
    "\n",
    "openai = LLM(\"openai\", proxy_config=proxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llmstudio.engine.provider.LLMProxyProvider at 0x10e1e9c10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai._provider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='7a435f11-ab93-473e-b439-37202e554a1f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I don’t have a personal name, but you can call me Assistant. How can I help you today?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729076083, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output='I don’t have a personal name, but you can call me Assistant. How can I help you today?', chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729076085.7050822, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 22, 'total_tokens': 26, 'cost_usd': 0.00035, 'latency_s': 3.0498709678649902, 'time_to_first_token_s': 0.5896170139312744, 'inter_token_latency_s': 0.10692943697390349, 'tokens_per_second': 7.869185369766901})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.chat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='a94bffc5-88ab-4290-8cce-d349c9829e57', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I’m called ChatGPT. How can I assist you today?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729076085, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output='I’m called ChatGPT. How can I assist you today?', chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729076086.277256, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 14, 'total_tokens': 18, 'cost_usd': 0.00023, 'latency_s': 0.5512211322784424, 'time_to_first_token_s': 0.3975660800933838, 'inter_token_latency_s': 0.010929771832057409, 'tokens_per_second': 27.212309401126042})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await openai.achat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, often referred to as the cosmos, is an expansive and mysterious expanse that extends beyond\n",
      "\n",
      " Earth's atmosphere. It is a vast, seemingly infinite realm filled with celestial bodies such as stars, planets\n",
      "\n",
      ", meteoroids, comets, and galaxies, each exhibiting unique characteristics and phenomena. The study\n",
      "\n",
      " of space, known as astronomy, has intrigued humans for millennia, driving them to explore and understand\n",
      "\n",
      " the universe's origins, structure, and future. With advancements in technology, humans have embarked on remarkable\n",
      "\n",
      " journeys into space, from landing on the Moon to deploying telescopes like the Hubble Space Telescope,\n",
      "\n",
      " which capture breathtaking images of distant galaxies and nebulas. Despite these achievements, the cosmos remains largely unexpl\n",
      "\n",
      "ored and holds countless mysteries, fueling our curiosity about the possibility of extraterrestrial life, the nature of\n",
      "\n",
      " dark matter and dark energy, and the ultimate fate of the universe itself. The exploration of space continues\n",
      "\n",
      " to inspire innovation, collaboration, and a profound sense of wonder, reminding us of our small yet significant\n",
      "\n",
      " place in the grand scheme of the universe.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.0032050000000000004,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.01872186113202401,\n",
      " 'latency_s': 4.415300130844116,\n",
      " 'output_tokens': 211,\n",
      " 'time_to_first_token_s': 0.5010969638824463,\n",
      " 'tokens_per_second': 47.56188566503003,\n",
      " 'total_tokens': 219}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"Write a paragfraph about space\", model=\"gpt-4o\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, the vast expanse beyond our planet's atmosphere, is a realm of awe and mystery\n",
      "\n",
      " that has captivated humanity for centuries. It stretches infinitely, hosting a myriad of celestial bodies, including stars\n",
      "\n",
      ", planets, moons, asteroids, and comets, all bound by the forces of gravity.\n",
      "\n",
      " The cosmos is not just a backdrop for astronomical phenomena; it's a dynamic environment where the laws of physics\n",
      "\n",
      " come to life. Black holes bend time and space, while supernovae illuminate the cosmos with explosive\n",
      "\n",
      " brilliance. Beyond our Milky Way galaxy, billions of other galaxies swirl in a cosmic dance, each\n",
      "\n",
      " potentially hosting its own unique systems and perhaps even life. As we continue to explore this enigmatic frontier through\n",
      "\n",
      " telescopes and space missions, we uncover the origins of the universe, the nature of dark matter,\n",
      "\n",
      " and the possibility of extraterrestrial life, igniting our imagination and expanding our understanding of existence itself.\n",
      "\n",
      "\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.0001098,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.027061593532562257,\n",
      " 'latency_s': 5.691463232040405,\n",
      " 'output_tokens': 181,\n",
      " 'time_to_first_token_s': 0.8199222087860107,\n",
      " 'tokens_per_second': 31.802015162120444,\n",
      " 'total_tokens': 189}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "async for chunk in await openai.achat(\"Write a paragfraph about space\", model=\"gpt-4o-mini\", is_stream=True):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio import LLM\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3 = LLM('openai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LLM' object has no attribute 'run_batch_chat_coroutine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m complex_prompt\u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a tchill dude from jamaica\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      2\u001b[0m           {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, how are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      3\u001b[0m           {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYe man doin fain man!\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      4\u001b[0m           {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow is the weather today?\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[1;32m      6\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms your name?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me a joke.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     complex_prompt\n\u001b[1;32m     13\u001b[0m ]\n\u001b[0;32m---> 15\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[43mgpt3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_batch_chat_coroutine\u001b[49m(inputs)\n\u001b[1;32m     16\u001b[0m responses\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LLM' object has no attribute 'run_batch_chat_coroutine'"
     ]
    }
   ],
   "source": [
    "complex_prompt= [{\"role\": \"system\", \"content\": \"You are a tchill dude from jamaica\"},\n",
    "          {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "          {\"role\": \"assistant\", \"content\": \"Ye man doin fain man!\"},\n",
    "          {\"role\": \"user\", \"content\": \"How is the weather today?\"}]\n",
    "\n",
    "inputs = [\n",
    "    \"What's your name?\",\n",
    "    \"Tell me a joke.\",\n",
    "    \"What's the weather like?\",\n",
    "    \"Can you sing a song?\",\n",
    "    \"Tell me about yourself.\",\n",
    "    complex_prompt\n",
    "]\n",
    "\n",
    "responses = gpt3.run_batch_chat_coroutine(inputs)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
