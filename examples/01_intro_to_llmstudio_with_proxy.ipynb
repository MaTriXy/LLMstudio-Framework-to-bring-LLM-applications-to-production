{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LLMstudio - proxy\n",
    "\n",
    "This tutorial serves as an introduction to LLMstudio, a platform designed to facilitate interactions with large language models (LLMs) through a proxy server. By following this guide, users will learn how to set up and run a proxy server that acts as an intermediary between the client and the LLM provider, ensuring seamless communication and data handling. The notebook demonstrates the process of initializing the server, configuring the proxy, and making requests to the LLM, providing a comprehensive overview of the system's capabilities.\n",
    "\n",
    "Additionally, the tutorial highlights the integration of tracking features within LLMstudio, allowing users to monitor and log interactions with the LLMs. This is particularly useful for analyzing performance metrics, such as latency and token usage, which can help in optimizing the model's responses and understanding its behavior in different scenarios. By the end of this tutorial, users will have a solid foundation in setting up and utilizing LLMstudio for efficient and effective LLM interactions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start proxy server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxy server already running on 0.0.0.0:8001\n"
     ]
    }
   ],
   "source": [
    "from llmstudio.server import start_servers\n",
    "\n",
    "# default port is 50001. set the environment varible to specify which host and port; LLMSTUDIO_ENGINE_HOST, LLMSTUDIO_ENGINE_PORT\n",
    "start_servers(proxy=True, tracker=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to LLMStudio Proxy @ 0.0.0.0:8001\n"
     ]
    }
   ],
   "source": [
    "from llmstudio_proxy.provider import LLMProxyProvider as LLM\n",
    "from llmstudio_proxy.provider import ProxyConfig\n",
    "\n",
    "llm = LLM(provider=\"openai\", \n",
    "          proxy_config=ProxyConfig(host=\"0.0.0.0\", port=\"8001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.chat(\"olá\", model=\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Olá! Como posso ajudá-lo hoje?',\n",
       " {'input_tokens': 2,\n",
       "  'output_tokens': 11,\n",
       "  'total_tokens': 13,\n",
       "  'cost_usd': 0.000175,\n",
       "  'latency_s': 0.8093140125274658,\n",
       "  'time_to_first_token_s': 0.541956901550293,\n",
       "  'inter_token_latency_s': 0.028835773468017578,\n",
       "  'tokens_per_second': 12.356143406896255})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.chat_output, result.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the LLMStudio SDK entrypoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio.providers import LLM\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host='0.0.0.0' port='8001' url=None username=None password=None\n",
      "Connected to LLMStudio Proxy @ 0.0.0.0:8001\n"
     ]
    }
   ],
   "source": [
    "# You can set OPENAI_API_KEY and ANTHROPIC_API_KEY on .env file\n",
    "from llmstudio_proxy.provider import ProxyConfig\n",
    "proxy = ProxyConfig(host=\"0.0.0.0\", port=\"8001\")\n",
    "print(proxy)\n",
    "\n",
    "openai = LLM(\"openai\", proxy_config=proxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llmstudio_proxy.provider.LLMProxyProvider at 0x121ae55b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai._provider\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='fb38ddcd-d53d-464a-af4d-99de07cb4659', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I’m called ChatGPT! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729702067, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output='I’m called ChatGPT! How can I assist you today?', chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729702067.576836, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 14, 'total_tokens': 18, 'cost_usd': 0.00023, 'latency_s': 0.6081359386444092, 'time_to_first_token_s': 0.44050097465515137, 'inter_token_latency_s': 0.011918153081621443, 'tokens_per_second': 24.665537829315557})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.chat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "result = await openai.achat(\"What's your name\", model=\"gpt-4o\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, the vast and enigmatic expanse beyond Earth's atmosphere, has captivated human imagination for centuries.\n",
      "\n",
      " It is a realm of infinite possibilities, where stars twinkle like distant beacons and galaxies swirl in\n",
      "\n",
      " cosmic dances. Within this boundless void lie the mysteries of black holes, neutron stars, and dark\n",
      "\n",
      " matter, challenging our understanding of physics and the universe itself. Space exploration, driven by a desire to\n",
      "\n",
      " explore and learn, has led to remarkable achievements, from landing on the moon to sending probes to distant\n",
      "\n",
      " planets and beyond. As technology advances, our ability to explore and understand space grows, promising new insights\n",
      "\n",
      " into the origins of our universe and the potential for life beyond our planet. The final frontier continues to\n",
      "\n",
      " inspire and beckon, reminding us of our small but significant place in the cosmos.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.002425,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.015780606846900504,\n",
      " 'latency_s': 3.448375940322876,\n",
      " 'output_tokens': 159,\n",
      " 'time_to_first_token_s': 0.9701387882232666,\n",
      " 'tokens_per_second': 45.81867021877152,\n",
      " 'total_tokens': 167}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"Write a paragfraph about space\", model=\"gpt-4o\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space is a vast and enigmatic expanse that extends beyond the confines of our planet, holding the\n",
      "\n",
      " mysteries of the universe within its dark, star-studded fabric. It is where galaxies collide,\n",
      "\n",
      " stars are born in stellar nurseries, and black holes warp the very fabric of time and space.\n",
      "\n",
      " The sheer scale of space is beyond human comprehension; it encompasses billions of galaxies, each containing millions or\n",
      "\n",
      " even billions of stars, along with myriad planets, moons, and celestial phenomena. As humanity ventures further\n",
      "\n",
      " into this cosmic wilderness, from the Moon to Mars and beyond, we continue to unravel the secrets of\n",
      "\n",
      " our origins and the potential for life beyond Earth. The exploration of space not only fuels our curiosity but\n",
      "\n",
      " also challenges our understanding of physics, chemistry, and the fundamental laws that govern the universe, inviting us\n",
      "\n",
      " to ponder our place in the grandeur of existence.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.0001032,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.017089052761302275,\n",
      " 'latency_s': 3.5080549716949463,\n",
      " 'output_tokens': 170,\n",
      " 'time_to_first_token_s': 0.6024937629699707,\n",
      " 'tokens_per_second': 48.74496020721703,\n",
      " 'total_tokens': 178}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "async for chunk in await openai.achat(\"Write a paragfraph about space\", model=\"gpt-4o-mini\", is_stream=True):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
