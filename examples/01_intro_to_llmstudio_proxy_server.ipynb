{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LLMstudio\n",
    "In this tutorial you'll be running the proxy and the tracker so you can automatically log the usage metrics and costs in the default database (`llmstudio_mgmt.db`).\n",
    "\n",
    "You'll learn:\n",
    "1. How to connect to any provider available (VertexAI, OpenAI, etc.)\n",
    "2. Make sync and async calls both with and without streaming\n",
    "3. See the save logs\n",
    "\n",
    "First things first:\n",
    "* run `pip install llmstudio[proxy, tracker]`\n",
    "* update your .env file with `GOOGLE_API_KEY` or `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start proxy and tracking servers\n",
    "This step is to set the proxy and tracking servers.\n",
    "You can opt out to start such servers (see `llmstudio-core` for the lightest version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLMstudio Proxy on http://0.0.0.0:8001 \n",
      "Running LLMstudio Tracking on http://0.0.0.0:8002 \n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from llmstudio.server import start_servers\n",
    "from llmstudio_tracker.tracker import TrackingConfig\n",
    "from llmstudio_proxy.provider import ProxyConfig\n",
    "\n",
    "# start servers\n",
    "start_servers(proxy=True, tracker=True)\n",
    "\n",
    "proxy = ProxyConfig(host=\"0.0.0.0\", port=\"8001\")\n",
    "tracking = TrackingConfig(host=\"0.0.0.0\", port=\"8002\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to LLMStudio Proxy @ 0.0.0.0:8001\n",
      "Connected to LLMStudio Proxy @ 0.0.0.0:8001\n"
     ]
    }
   ],
   "source": [
    "from llmstudio.providers import LLM\n",
    "\n",
    "# You can set OPENAI_API_KEY and GOOGLE_API_KEY on .env file or pass as api_key on LLM\n",
    "\n",
    "vertexai = LLM(\"vertexai\",\n",
    "               proxy_config=proxy,\n",
    "               tracking_config=tracking,\n",
    "               session_id=\"vertexai-1\")\n",
    "\n",
    "openai = LLM(\"openai\",\n",
    "             proxy_config=proxy,\n",
    "             tracking_config=tracking,\n",
    "             session_id=\"openai-1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VertexAI\n",
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have a name. I am a large language model, here to assist you with any questions or tasks you may have. ðŸ˜Š \n",
      "\n",
      "How can I help you today? \n",
      "\n",
      "{'cost_usd': 0.0004004,\n",
      " 'input_tokens': 4,\n",
      " 'inter_token_latency_s': 0.10699827330453056,\n",
      " 'latency_s': 2.0291249752044678,\n",
      " 'output_tokens': 38,\n",
      " 'time_to_first_token_s': 1.248373031616211,\n",
      " 'tokens_per_second': 3.9425861382411242,\n",
      " 'total_tokens': 42}\n"
     ]
    }
   ],
   "source": [
    "response = vertexai.chat(\"What's your name\", model=\"gemini-1.5-pro-latest\")\n",
    "print(response.chat_output)\n",
    "pprint(response.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Async (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='c5d0d059-ace9-413a-b30c-8a339e0f9225', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I am a large language model, trained by Google. I don't have a name like humans do. \\n\\nHow can I assist you today? ðŸ˜Š \\n\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729545819, model='gemini-1.5-pro-latest', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output=\"I am a large language model, trained by Google. I don't have a name like humans do. \\n\\nHow can I assist you today? ðŸ˜Š \\n\", chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='vertexai', deployment='gemini-1.5-pro-latest', timestamp=1729545819.9707232, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 32, 'total_tokens': 36, 'cost_usd': 0.00033739999999999996, 'latency_s': 1.7530958652496338, 'time_to_first_token_s': 1.070990800857544, 'inter_token_latency_s': 0.0922797407422747, 'tokens_per_second': 4.563355694676076})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await vertexai.achat(\"What's your name\", model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, a boundless expanse of darkness sprinkled with the brilliance of celestial objects, has captivated\n",
      "\n",
      " humanity for millennia. From the twinkling stars in our Milky Way galaxy to the swirling gases of distant nebulas, the universe offers an endless panorama of wonder. It's a realm where gravity sculpts galaxies, where stars are born and\n",
      "\n",
      " extinguished in fiery explosions, and where planets, some potentially harboring life, orbit their suns in a delicate cosmic dance. Exploring this final frontier, pushing the boundaries of human knowledge and daring to venture into the unknown, continues to inspire us, fueling our curiosity about the origins of the universe and our place within it. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.0014518,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.22149918296120383,\n",
      " 'latency_s': 3.5945589542388916,\n",
      " 'output_tokens': 138,\n",
      " 'time_to_first_token_s': 1.140388011932373,\n",
      " 'tokens_per_second': 3.3383789646429287,\n",
      " 'total_tokens': 146}\n"
     ]
    }
   ],
   "source": [
    "response = vertexai.chat(\"Write a paragfraph about space\", model=\"gemini-1.5-pro-latest\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%2==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Async (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space, a vast and enigmatic expanse, stretches out beyond the bounds of our planet,\n",
      "\n",
      " holding countless mysteries and wonders. Stars, like celestial diamonds, twinkle against the inky blackness, their light traveling for eons to reach our eyes. Planets, both familiar and alien, orbit distant suns, each with its own unique story to tell. Nebulas, clouds of gas and dust, paint the cosmos with vibrant hues, while galaxies, vast collections of stars, stretch out like celestial tapestries across the universe. From the smallest particles to the largest structures, space is a realm of endless fascination, inviting us to explore its depths and unravel its secrets. \n",
      "\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.0014413,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.22311646288091486,\n",
      " 'latency_s': 3.6461358070373535,\n",
      " 'output_tokens': 137,\n",
      " 'time_to_first_token_s': 1.1856458187103271,\n",
      " 'tokens_per_second': 3.2911555232909797,\n",
      " 'total_tokens': 145}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "async for chunk in await vertexai.achat(\"Write a paragfraph about space\", model=\"gemini-1.5-pro-latest\", is_stream=True):\n",
    "    if i%20==2:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get session metrics and usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio_tracker.tracker import Tracker\n",
    "\n",
    "tracker = Tracker(tracking_config=tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_input': \"What's your name\",\n",
       " 'chat_output': \"I don't have a name. I am a large language model, here to assist you with any questions or tasks you may have. ðŸ˜Š \\n\\nHow can I help you today? \\n\",\n",
       " 'session_id': 'vertexai-1',\n",
       " 'context': [{'role': 'user', 'content': \"What's your name\"}],\n",
       " 'provider': 'vertexai',\n",
       " 'model': 'gemini-1.5-pro-latest',\n",
       " 'deployment': 'gemini-1.5-pro-latest',\n",
       " 'parameters': {},\n",
       " 'metrics': {'input_tokens': 4,\n",
       "  'output_tokens': 38,\n",
       "  'total_tokens': 42,\n",
       "  'cost_usd': 0.0004004,\n",
       "  'latency_s': 2.0291249752044678,\n",
       "  'time_to_first_token_s': 1.248373031616211,\n",
       "  'inter_token_latency_s': 0.10699827330453056,\n",
       "  'tokens_per_second': 3.9425861382411242},\n",
       " 'log_id': 1,\n",
       " 'created_at': '2024-10-21T21:23:38'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = tracker.get_session_logs(session_id=\"vertexai-1\")\n",
    "logs.json()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI\n",
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iâ€™m called Assistant, but you can name me whatever youâ€™d like! How can I help you today?\n",
      "{'cost_usd': 0.00035,\n",
      " 'input_tokens': 4,\n",
      " 'inter_token_latency_s': 0.014487525691156801,\n",
      " 'latency_s': 1.730828046798706,\n",
      " 'output_tokens': 22,\n",
      " 'time_to_first_token_s': 1.3967618942260742,\n",
      " 'tokens_per_second': 13.866195457364912,\n",
      " 'total_tokens': 26}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"What's your name\", model=\"gpt-4o\")\n",
    "print(response.chat_output)\n",
    "pprint(response.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Async (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='68984d4b-6a9e-4b62-9af5-195ab901ad83', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Iâ€™m an AI language model created by OpenAI, and I donâ€™t have a personal name. You can call me Assistant if youâ€™d like!', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729545829, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output='Iâ€™m an AI language model created by OpenAI, and I donâ€™t have a personal name. You can call me Assistant if youâ€™d like!', chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729545830.260567, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 30, 'total_tokens': 34, 'cost_usd': 0.00047, 'latency_s': 1.1592588424682617, 'time_to_first_token_s': 0.7933480739593506, 'inter_token_latency_s': 0.011781254122334143, 'tokens_per_second': 27.603843790284564})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await openai.achat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, the vast expanse beyond our Earth's atmosphere, is an awe-inspiring realm that has\n",
      "\n",
      " captivated the human imagination for centuries. It is a place of endless wonder and profound mystery, where galaxies\n",
      "\n",
      ", stars, planets, and celestial bodies float in a delicate cosmic dance. The exploration of space has\n",
      "\n",
      " led to groundbreaking discoveries, from the intricate details of our own solar system to the revelation of distant ex\n",
      "\n",
      "oplanets that might harbor life. Space is not only a scientific frontier but also a source of philosophical\n",
      "\n",
      " contemplation, challenging us to ponder our place in the universe and inspiring a sense of unity among humankind\n",
      "\n",
      " as we look beyond our terrestrial home. As technology advances, space travel and research continue to push the\n",
      "\n",
      " boundaries of what we know, constantly redefining our understanding of the cosmos and our place within it.\n",
      "\n",
      "\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.0024850000000000002,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.011184079945087433,\n",
      " 'latency_s': 2.1537232398986816,\n",
      " 'output_tokens': 163,\n",
      " 'time_to_first_token_s': 0.3636894226074219,\n",
      " 'tokens_per_second': 74.7542660158944,\n",
      " 'total_tokens': 171}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"Write a paragfraph about space\", model=\"gpt-4o\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Async (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, the vast and infinite expanse that exists beyond our planet, is a realm of wonder\n",
      "\n",
      " and mystery that captivates the human imagination. It is home to billions of galaxies, each containing countless\n",
      "\n",
      " stars and celestial bodies, including planets, moons, and asteroids. The sheer scale of space is\n",
      "\n",
      " difficult to comprehend, with distances measured in light-years, illuminating the vast chasms between stars.\n",
      "\n",
      " Within this cosmos, phenomena such as black holes, supernovae, and neutron stars challenge our understanding\n",
      "\n",
      " of physics and the universe's very nature. Beyond its physical attributes, space invites philosophical contemplation about our\n",
      "\n",
      " place in the universe, the possibility of extraterrestrial life, and the future of humanity as we continue\n",
      "\n",
      " to explore and expand our reach into the cosmos. As technology advances, our efforts to unveil the secrets\n",
      "\n",
      " of space may one day reveal answers to questions that have intrigued humanity for centuries.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.000108,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.032924545082178985,\n",
      " 'latency_s': 6.334553003311157,\n",
      " 'output_tokens': 178,\n",
      " 'time_to_first_token_s': 0.5375351905822754,\n",
      " 'tokens_per_second': 27.941987367929464,\n",
      " 'total_tokens': 186}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "async for chunk in await openai.achat(\"Write a paragfraph about space\", model=\"gpt-4o-mini\", is_stream=True):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio_tracker.tracker import Tracker\n",
    "\n",
    "tracker = Tracker(tracking_config=tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_input': \"What's your name\",\n",
       " 'chat_output': 'Iâ€™m called Assistant, but you can name me whatever youâ€™d like! How can I help you today?',\n",
       " 'session_id': 'openai-1',\n",
       " 'context': [{'role': 'user', 'content': \"What's your name\"}],\n",
       " 'provider': 'openai',\n",
       " 'model': 'gpt-4o',\n",
       " 'deployment': 'gpt-4o-2024-08-06',\n",
       " 'parameters': {},\n",
       " 'metrics': {'input_tokens': 4,\n",
       "  'output_tokens': 22,\n",
       "  'total_tokens': 26,\n",
       "  'cost_usd': 0.00035,\n",
       "  'latency_s': 1.730828046798706,\n",
       "  'time_to_first_token_s': 1.3967618942260742,\n",
       "  'inter_token_latency_s': 0.014487525691156801,\n",
       "  'tokens_per_second': 13.866195457364912},\n",
       " 'log_id': 5,\n",
       " 'created_at': '2024-10-21T21:23:49'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = tracker.get_session_logs(session_id=\"openai-1\")\n",
    "logs.json()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
