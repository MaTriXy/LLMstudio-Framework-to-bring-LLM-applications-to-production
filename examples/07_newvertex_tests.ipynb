{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLMstudio Engine on http://localhost:50001 Running LLMstudio Tracking on http://localhost:50002 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llmstudio import LLM\n",
    "import os\n",
    "import json\n",
    "import dotenv\n",
    "import requests\n",
    "\n",
    "# Load environment variables from .env file\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Raw Vertex Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gemini-1.5-flash'\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "url = f\"https://generativelanguage.googleapis.com/v1beta/models/{model}:streamGenerateContent?alt=sse\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"x-goog-api-key\": api_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator = [\n",
    "      {'name': 'multiply',\n",
    "       'description': 'Returns the product of two numbers.',\n",
    "       'parameters': {'type_': 'OBJECT',\n",
    "       'properties': {\n",
    "         'a': {'type_': 'NUMBER'},\n",
    "         'b': {'type_': 'NUMBER'} },\n",
    "       'required': ['a', 'b']} }]\n",
    "\n",
    "calculator_2 = \"\"\"function_declarations {\n",
    "  name: \"multiply\"\n",
    "  description: \"Returns the product of two numbers.\"\n",
    "  parameters {\n",
    "    type_: OBJECT\n",
    "    properties {\n",
    "      key: \"b\"\n",
    "      value {\n",
    "        type_: NUMBER\n",
    "      }\n",
    "    }\n",
    "    properties {\n",
    "      key: \"a\"\n",
    "      value {\n",
    "        type_: NUMBER\n",
    "      }\n",
    "    }\n",
    "    required: \"a\"\n",
    "    required: \"b\"\n",
    "  }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'What is 9 times 10?'\n",
    "data = {\n",
    "  \"system_instruction\": {\n",
    "    \"parts\": {\n",
    "      \"text\": \"\"\n",
    "    }\n",
    "  },\n",
    "  \"contents\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"parts\": [\n",
    "        {\n",
    "          \"text\": \"How many legs does a spider have?\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url, headers=headers, json=data, stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"A\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0}],\"usageMetadata\": {\"promptTokenCount\": 9,\"candidatesTokenCount\": 1,\"totalTokenCount\": 10}}\\r\\n\\r\\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" spider has **eight** legs. \\\\n\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}],\"usageMetadata\": {\"promptTokenCount\": 9,\"candidatesTokenCount\": 8,\"totalTokenCount\": 17}}\\r\\n\\r\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vertex Functions Tests - Str to OAI to Vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"system_instruction\": {\n",
      "    \"parts\": {\n",
      "      \"text\": \"\"\n",
      "    }\n",
      "  },\n",
      "  \"contents\": [\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"parts\": [\n",
      "        {\n",
      "          \"text\": \"How many legs does a spider have?\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"system_instruction\": {\n",
      "    \"parts\": {\n",
      "      \"text\": \"You are a helpful assistant.\"\n",
      "    }\n",
      "  },\n",
      "  \"contents\": [\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"parts\": [\n",
      "        {\n",
      "          \"text\": \"Hello\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"model\",\n",
      "      \"parts\": [\n",
      "        {\n",
      "          \"text\": \"Hi there!\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Error: Input must be a list of dictionaries, each containing 'role' and 'content' keys.\n"
     ]
    }
   ],
   "source": [
    "def convert_openai_to_vertexai(input_data):\n",
    "    # Check if the input is a simple string\n",
    "    if isinstance(input_data, str):\n",
    "        # Return a Vertex AI formatted message with a user message\n",
    "        return {\n",
    "            \"system_instruction\": {\n",
    "                \"parts\": {\n",
    "                    \"text\": \"\"  # Empty system instruction\n",
    "                }\n",
    "            },\n",
    "            \"contents\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"parts\": [{\"text\": input_data}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # Validate if input_data is a list and each element is a dictionary with the correct structure\n",
    "    if not isinstance(input_data, list) or not all(isinstance(msg, dict) and 'role' in msg and 'content' in msg for msg in input_data):\n",
    "        raise ValueError(\"Input must be a list of dictionaries, each containing 'role' and 'content' keys.\")\n",
    "\n",
    "    # Initialize the Vertex AI format if the input is not a simple string\n",
    "    vertexai_format = {\n",
    "        \"system_instruction\": {\n",
    "            \"parts\": {\n",
    "                \"text\": \"\"\n",
    "            }\n",
    "        },\n",
    "        \"contents\": []\n",
    "    }\n",
    "    \n",
    "    # Loop through the OpenAI formatted messages\n",
    "    for message in input_data:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            # Set the system instruction\n",
    "            vertexai_format[\"system_instruction\"][\"parts\"][\"text\"] = message[\"content\"]\n",
    "        elif message[\"role\"] in [\"user\", \"assistant\"]:\n",
    "            # Convert roles: 'assistant' -> 'model'\n",
    "            role = \"model\" if message[\"role\"] == \"assistant\" else \"user\"\n",
    "            # Append the message to the contents list in Vertex AI format\n",
    "            vertexai_format[\"contents\"].append({\n",
    "                \"role\": role,\n",
    "                \"parts\": [{\"text\": message[\"content\"]}]\n",
    "            })\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid role: {message['role']}. Expected 'system', 'user', or 'assistant'.\")\n",
    "    \n",
    "    return vertexai_format\n",
    "\n",
    "# Example usage with a string input\n",
    "simple_input = \"How many legs does a spider have?\"\n",
    "vertexai_format = convert_openai_to_vertexai(simple_input)\n",
    "print(json.dumps(vertexai_format, indent=2))\n",
    "\n",
    "# Example usage with a valid list of OpenAI messages\n",
    "openai_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi there!\"}\n",
    "]\n",
    "vertexai_format = convert_openai_to_vertexai(openai_messages)\n",
    "print(json.dumps(vertexai_format, indent=2))\n",
    "\n",
    "# Example usage with an invalid input to trigger an error\n",
    "try:\n",
    "    invalid_input = [\n",
    "        {\"role\": \"system\", \"text\": \"You are a helpful assistant.\"}  # 'text' should be 'content'\n",
    "    ]\n",
    "    vertexai_format = convert_openai_to_vertexai(invalid_input)\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Vertex Chat test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLMstudio Engine on http://localhost:50001 Running LLMstudio Tracking on http://localhost:50002 \n",
      "\n",
      "tools: None\n",
      "message: {'system_instruction': {'parts': {'text': 'You are a helpful assistant'}}, 'contents': [{'role': 'user', 'parts': [{'text': 'Hello'}]}], 'tools': None, 'tool_config': {'function_calling_config': {'mode': 'AUTO'}}}\n",
      "chunk: {'parts': [{'text': 'Hello'}], 'role': 'model'}\n",
      "chunk: {'parts': [{'text': '! 👋  What can I do for you today? 😊 \\n'}], 'role': 'model'}\n"
     ]
    }
   ],
   "source": [
    "llm = LLM('newvertex/gemini-1.5-pro-latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 String format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='0b661363-776e-48a3-a65e-6e0d08306ec8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! 👋  What can I do for you today? 😊 \\n', role='assistant', function_call=None, tool_calls=None))], created=1723800713, model='gemini-1.5-pro-latest', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Hello', chat_output='Hello! 👋  What can I do for you today? 😊 \\n', context=[{'role': 'user', 'content': 'Hello'}], provider='newvertex', deployment='gemini-1.5-pro-latest', timestamp=1723800713.506577, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 1, 'output_tokens': 16, 'total_tokens': 17, 'cost_usd': 1.7149999999999997e-05, 'latency_s': 1.8147468566894531, 'time_to_first_token_s': 1.448904037475586, 'inter_token_latency_s': 0.11205267906188965, 'tokens_per_second': 2.204164170476641})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.chat('Hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 OpenAI format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='7fa9938b-1ec8-4b7a-a89b-34c0bb779dd0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Aright man, mi deh yah a gwaan! How tings gwaan wid you?  🇯🇲 😄 \\n\\n(Translation: I'm doing well, how are you?) \\n\", role='assistant', function_call=None, tool_calls=None))], created=1723799492, model='gemini-1.5-pro-latest', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Hello, how are you?', chat_output=\"Aright man, mi deh yah a gwaan! How tings gwaan wid you?  🇯🇲 😄 \\n\\n(Translation: I'm doing well, how are you?) \\n\", context=[{'role': 'system', 'content': 'You are Jamaican.'}, {'role': 'assistant', 'content': 'How can i help you?'}, {'role': 'user', 'content': 'Hello, how are you?'}], provider='newvertex', deployment='gemini-1.5-pro-latest', timestamp=1723799492.7148879, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 16, 'output_tokens': 46, 'total_tokens': 62, 'cost_usd': 5.3899999999999996e-05, 'latency_s': 2.1366829872131348, 'time_to_first_token_s': 1.3183910846710205, 'inter_token_latency_s': 0.11596315247671944, 'tokens_per_second': 3.7441211671902535})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = [{\"role\": \"system\", \"content\": \"You are Jamaican.\"},\n",
    "           {\"role\": \"assistant\", \"content\": \"How can i help you?\"},\n",
    "           {\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n",
    "\n",
    "llm.chat(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Vertex function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = {\n",
    "  \"function_declarations\": [\n",
    "    {\n",
    "      \"name\": \"get_weather\",\n",
    "      \"description\": \"Gets the weather for a certain location.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The location we are getting the weather for. For example: San Francisco\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"location\"\n",
    "        ]\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"get_time\",\n",
    "      \"description\": \"Gets the current time for a certain location.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The location we are getting the current time for. For example: New York\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"location\"  \n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLMstudio Tracking on http://localhost:50002 \n",
      "Running LLMstudio Engine on http://localhost:50001 \n"
     ]
    }
   ],
   "source": [
    "from llmstudio import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM('newvertex/gemini-1.5-pro-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tools: {'function_declarations': [{'name': 'get_weather', 'description': 'Gets the weather for a certain location.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location we are getting the weather for. For example: San Francisco'}}, 'required': ['location']}}, {'name': 'get_time', 'description': 'Gets the current time for a certain location.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location we are getting the current time for. For example: New York'}}, 'required': ['location']}}]}\n",
      "message: {'system_instruction': {'parts': {'text': 'You are a helpful assistant'}}, 'contents': [{'role': 'user', 'parts': [{'text': 'Hello'}]}], 'tools': {'function_declarations': [{'name': 'get_weather', 'description': 'Gets the weather for a certain location.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location we are getting the weather for. For example: San Francisco'}}, 'required': ['location']}}, {'name': 'get_time', 'description': 'Gets the current time for a certain location.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location we are getting the current time for. For example: New York'}}, 'required': ['location']}}]}, 'tool_config': {'function_calling_config': {'mode': 'AUTO'}}}\n",
      "chunk: b'data: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"Hello\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0}],\"usageMetadata\": {\"promptTokenCount\": 115,\"candidatesTokenCount\": 1,\"totalTokenCount\": 116}}\\r\\n\\r\\n'\n",
      "chunk: b'data: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"! \\xf0\\x9f\\x91\\x8b  What can I do for you today? \\xf0\\x9f\\x98\\x8a \\\\n\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}],\"usageMetadata\": {\"promptTokenCount\": 115,\"candidatesTokenCount\": 13,\"totalTokenCount\": 128}}\\r\\n\\r\\n'\n",
      "tools: {'function_declarations': [{'name': 'get_weather', 'description': 'Gets the weather for a certain location.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location we are getting the weather for. For example: San Francisco'}}, 'required': ['location']}}, {'name': 'get_time', 'description': 'Gets the current time for a certain location.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location we are getting the current time for. For example: New York'}}, 'required': ['location']}}]}\n",
      "message: {'system_instruction': {'parts': {'text': 'You are a helpfull assistant'}}, 'contents': [{'role': 'model', 'parts': [{'text': 'How can i help you?'}]}, {'role': 'user', 'parts': [{'text': 'What time is it in San Francisco? And what is the weather there?'}]}], 'tools': {'function_declarations': [{'name': 'get_weather', 'description': 'Gets the weather for a certain location.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location we are getting the weather for. For example: San Francisco'}}, 'required': ['location']}}, {'name': 'get_time', 'description': 'Gets the current time for a certain location.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location we are getting the current time for. For example: New York'}}, 'required': ['location']}}]}, 'tool_config': {'function_calling_config': {'mode': 'AUTO'}}}\n",
      "chunk: b'data: {\"candidates\": [{\"content\": {\"parts\": [{\"functionCall\": {\"name\": \"get_time\",\"args\": {\"location\": \"San Francisco\"}}},{\"functionCall\": {\"name\": \"get_weather\",\"args\": {\"location\": \"San Francisco\"}}}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"}]}],\"usageMetadata\": {\"promptTokenCount\": 137,\"candidatesTokenCount\": 32,\"totalTokenCount\": 169}}\\r\\n\\r\\n'\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "async generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m message \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpfull assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      2\u001b[0m            {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow can i help you?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      3\u001b[0m            {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat time is it in San Francisco? And what is the weather there?\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[1;32m      5\u001b[0m llm\u001b[38;5;241m.\u001b[39mchat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHello\u001b[39m\u001b[38;5;124m'\u001b[39m, tools \u001b[38;5;241m=\u001b[39m functions)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/LLMstudio/llmstudio/llm/__init__.py:70\u001b[0m, in \u001b[0;36mLLM.chat\u001b[0;34m(self, input, is_stream, retries, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m         error_data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_data)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_stream:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_chat(response)\n",
      "\u001b[0;31mException\u001b[0m: async generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "message = [{\"role\": \"system\", \"content\": \"You are a helpfull assistant\"},\n",
    "           {\"role\": \"assistant\", \"content\": \"How can i help you?\"},\n",
    "           {\"role\": \"user\", \"content\": \"What time is it in San Francisco? And what is the weather there?\"}]\n",
    "\n",
    "llm.chat('Hello', tools = functions)\n",
    "llm.chat(message, tools = functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = {'parts': [{'functionCall': {'name': 'get_time', 'args': {'location': 'San Francisco'}}}, {'functionCall': {'name': 'get_weather', 'args': {'location': 'San Francisco'}}}], 'role': 'model'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'functionCall': {'name': 'get_time', 'args': {'location': 'San Francisco'}}}\n",
      "{'functionCall': {'name': 'get_weather', 'args': {'location': 'San Francisco'}}}\n"
     ]
    }
   ],
   "source": [
    "if 'functionCall' in chunk['parts'][0]:\n",
    "    for functioncall in  enumerate(chunk['parts']):\n",
    "        print(functioncall)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Raw Vertex function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = {\n",
    "  \"function_declarations\": [\n",
    "    {\n",
    "      \"name\": \"get_weather\",\n",
    "      \"description\": \"Gets the weather for a certain location.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The location we are getting the weather for. For example: San Francisco\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"location\"\n",
    "        ]\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"get_time\",\n",
    "      \"description\": \"Gets the current time for a certain location.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The location we are getting the current time for. For example: New York\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"location\"  \n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions_json = json.dumps(functions)\n",
    "functions_obj = json.loads(functions_json)\n",
    "type(functions_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Hello! 👋  What can I do for you today? \\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0,\n",
      "      \"safetyRatings\": [\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "          \"probability\": \"NEGLIGIBLE\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "          \"probability\": \"NEGLIGIBLE\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "          \"probability\": \"NEGLIGIBLE\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "          \"probability\": \"NEGLIGIBLE\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 116,\n",
      "    \"candidatesTokenCount\": 12,\n",
      "    \"totalTokenCount\": 128\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "# Prepare the data for the API call\n",
    "api_key = os.getenv('GOOGLE_API_KEY')  # Replace this with your actual Google API key\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "data = {\n",
    "    \"system_instruction\": {\n",
    "        \"parts\": {\n",
    "            \"text\": \"You are a helpful assistant.\"\n",
    "        }\n",
    "    },\n",
    "    \"contents\": {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": {\n",
    "            \"text\": \"Hello\"\n",
    "        }\n",
    "    },\n",
    "    \"tools\": functions_obj,  # Use the parsed object instead of the JSON string\n",
    "    \"tool_config\": {\n",
    "        \"function_calling_config\": {\"mode\": \"AUTO\"}\n",
    "    },\n",
    "}\n",
    "\n",
    "# Make the API call\n",
    "response = requests.post(f'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key={api_key}',\n",
    "                         headers=headers, json=data, stream=True)\n",
    "\n",
    "# Print the response content\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. OpenAI tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_n_day_weather_forecast\",\n",
    "            \"description\": \"Get an N-day weather forecast\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                    \"num_days\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The number of days to forecast\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [{\"role\": \"system\", \"content\": \"You are a helpfull assistant\"},\n",
    "           {\"role\": \"assistant\", \"content\": \"How can i help you?\"},\n",
    "           {\"role\": \"user\", \"content\": \"What is the weather and time in San Francisco?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "            model='gpt-4o',\n",
    "            messages=message,\n",
    "            tools=tools,\n",
    "            stream=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id='call_NLnOYAVHFSnhQIeFWLigs9X0', function=ChoiceDeltaToolCallFunction(arguments='', name='get_current_weather'), type='function')]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='{\"lo', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='catio', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='n\": \"S', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='an F', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='ranci', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='sco, C', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='A\", ', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='\"form', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='at\": \"', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='fahr', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='enhei', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='t\"}', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=1, id='call_xLfhZ3sVzux3giLXaO8iLQ1t', function=ChoiceDeltaToolCallFunction(arguments='', name='get_current_time'), type='function')]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=1, id=None, function=ChoiceDeltaToolCallFunction(arguments='{\"lo', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=1, id=None, function=ChoiceDeltaToolCallFunction(arguments='catio', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=1, id=None, function=ChoiceDeltaToolCallFunction(arguments='n\": \"S', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=1, id=None, function=ChoiceDeltaToolCallFunction(arguments='an F', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=1, id=None, function=ChoiceDeltaToolCallFunction(arguments='ranci', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=1, id=None, function=ChoiceDeltaToolCallFunction(arguments='sco, C', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=1, id=None, function=ChoiceDeltaToolCallFunction(arguments='A\"}', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9wnOOsvDNSue0HFA6DDekjshTR9Qz', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='tool_calls', index=0, logprobs=None)], created=1723799916, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_3aa7262c27', usage=None)\n"
     ]
    }
   ],
   "source": [
    "for chunk in response:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmstudiodev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
