{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LLMstudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio import LLM\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set OPENAI_API_KEY and ANTHROPIC_API_KEY on .env file\n",
    "\n",
    "anthropic = LLM(\"vertexai\") # or you can pass api_key as an argument here\n",
    "openai = LLM(\"openai\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='57b0b582-2e1e-4288-b270-4d946fbc6eb6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I’m an AI language model created by OpenAI, and I don't have a personal name. You can call me whatever you like! How can I assist you today?\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1728991499, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output=\"I’m an AI language model created by OpenAI, and I don't have a personal name. You can call me whatever you like! How can I assist you today?\", context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1728991500.507817, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 35, 'total_tokens': 39, 'cost_usd': 0.000545, 'latency_s': 1.9663710594177246, 'time_to_first_token_s': 1.0656960010528564, 'inter_token_latency_s': 0.025410114015851703, 'tokens_per_second': 18.30783657417141})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.chat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='2d4fcafc-c19a-49ff-821a-e925abfb544c', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I’m called ChatGPT, your friendly AI assistant. How can I help you today?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1728991501, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output='I’m called ChatGPT, your friendly AI assistant. How can I help you today?', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1728991502.176515, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 19, 'total_tokens': 23, 'cost_usd': 0.000305, 'latency_s': 1.6578657627105713, 'time_to_first_token_s': 1.019500970840454, 'inter_token_latency_s': 0.03355515630621659, 'tokens_per_second': 12.06370289431665})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await openai.achat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, the vast expanse beyond Earth's atmosphere, is a realm of infinite possibilities and mysteries that\n",
      "\n",
      " has captivated human imagination for centuries. It encompasses everything from the smallest particles to massive celestial bodies like stars\n",
      "\n",
      ", planets, and galaxies. Space is a place where the laws of physics and the limits of human\n",
      "\n",
      " understanding are constantly tested and expanded. It holds the secrets of our origin, our place in the universe\n",
      "\n",
      ", and the potential for life beyond Earth. The exploration of space has led to significant technological and scientific\n",
      "\n",
      " advancements, and it continues to inspire a sense of wonder and curiosity. As we venture further into this\n",
      "\n",
      " great unknown, we are reminded of the boundless nature of the universe and our relentless quest for knowledge\n",
      "\n",
      ".\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.00217,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.0326266238029967,\n",
      " 'latency_s': 5.229671001434326,\n",
      " 'output_tokens': 142,\n",
      " 'time_to_first_token_s': 0.6259880065917969,\n",
      " 'tokens_per_second': 27.152759697704518,\n",
      " 'total_tokens': 150}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"Write a paragfraph about space\", model=\"gpt-4o\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, the vast and seemingly infinite expanse beyond our planet, captivates the human imagination with\n",
      "\n",
      " its profound mysteries and breathtaking beauty. It is home to an array of celestial phenomena, from the radiant\n",
      "\n",
      " glow of distant stars to the swirling patterns of galaxies, each revealing the complex tapestry of the universe.\n",
      "\n",
      " The vacuum of space, devoid of atmosphere, allows for the remarkable observation of cosmic events and the exploration\n",
      "\n",
      " of planets within our solar system and beyond. The study of space not only enhances our understanding of the\n",
      "\n",
      " fundamental laws of physics but also raises profound questions about the origins of life and our place in the cosmos\n",
      "\n",
      ". As humanity continues to push the boundaries of exploration, from robotic missions to manned spaceflights\n",
      "\n",
      ", we inch closer to unlocking the secrets that lie among the stars, fostering a sense of wonder that\n",
      "\n",
      " defines our quest to explore the unknown.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.000102,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.01550252948488508,\n",
      " 'latency_s': 3.185244083404541,\n",
      " 'output_tokens': 168,\n",
      " 'time_to_first_token_s': 0.579679012298584,\n",
      " 'tokens_per_second': 53.057158438974234,\n",
      " 'total_tokens': 176}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "async for chunk in await openai.achat(\"Write a paragfraph about space\", model=\"gpt-4o-mini\", is_stream=True):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if not chunk.metrics:\n",
    "        print(chunk.chat_output, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio import LLM\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gpt3 \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenai/gpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fun/LLMstudio/llmstudio/llm/__init__.py:39\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, provider, proxy_config, tracking_config, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_provider \u001b[38;5;241m=\u001b[39m LLMProxyProvider(provider\u001b[38;5;241m=\u001b[39mprovider,\n\u001b[1;32m     35\u001b[0m                                       host\u001b[38;5;241m=\u001b[39mproxy_config\u001b[38;5;241m.\u001b[39mhost,\n\u001b[1;32m     36\u001b[0m                                       port\u001b[38;5;241m=\u001b[39mproxy_config\u001b[38;5;241m.\u001b[39mport\n\u001b[1;32m     37\u001b[0m                                       )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_provider \u001b[38;5;241m=\u001b[39m \u001b[43mLLM_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session_local \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracking_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/fun/LLMstudio/libs/core/llmstudio_core/__init__.py:25\u001b[0m, in \u001b[0;36mLLM\u001b[0;34m(provider, api_key, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mFactory method to create an instance of a provider.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    NotImplementedError: If the provider is not found in the provider map.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m provider_config \u001b[38;5;241m=\u001b[39m _engine_config\u001b[38;5;241m.\u001b[39mproviders\u001b[38;5;241m.\u001b[39mget(provider)\n\u001b[0;32m---> 25\u001b[0m provider_class \u001b[38;5;241m=\u001b[39m provider_registry\u001b[38;5;241m.\u001b[39mget(\u001b[43mprovider_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m provider_class:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m provider_class(config\u001b[38;5;241m=\u001b[39mprovider_config, api_key\u001b[38;5;241m=\u001b[39mapi_key, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'id'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gpt3 = LLM('openai/gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletion(id='bce77107-790e-4194-b709-c1f973908e13', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I am a virtual assistant and I do not have a personal name. You can simply refer to me as \"assistant\". How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1718357127, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's your name?\", chat_output='I am a virtual assistant and I do not have a personal name. You can simply refer to me as \"assistant\". How can I assist you today?', context=[{'role': 'user', 'content': \"What's your name?\"}], provider='openai', timestamp=1718357130.3642838, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 5, 'output_tokens': 31, 'total_tokens': 36, 'cost_usd': 4.9e-05, 'latency_s': 2.8777408599853516, 'time_to_first_token_s': 2.8716890811920166, 'inter_token_latency_s': 8.686631917953491e-05, 'tokens_per_second': 11.46732857668358}),\n",
       " ChatCompletion(id='f5058611-d4e5-48cc-810f-5cfbf82bd70f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Why couldn't the bicycle find its way home? Because it lost its bearings!\", role='assistant', function_call=None, tool_calls=None))], created=1718357129, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Tell me a joke.', chat_output=\"Why couldn't the bicycle find its way home? Because it lost its bearings!\", context=[{'role': 'user', 'content': 'Tell me a joke.'}], provider='openai', timestamp=1718357130.392538, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 5, 'output_tokens': 16, 'total_tokens': 21, 'cost_usd': 2.65e-05, 'latency_s': 0.9708259105682373, 'time_to_first_token_s': 0.9693810939788818, 'inter_token_latency_s': 7.653236389160156e-05, 'tokens_per_second': 18.540914291692484}),\n",
       " ChatCompletion(id='bb195dce-30b4-4836-a9bc-9d73ea81efcc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm sorry, I am an AI and do not have the ability to determine the current weather. You can check the weather in your area by using a weather app on your phone or by visiting a weather website.\", role='assistant', function_call=None, tool_calls=None))], created=1718357129, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's the weather like?\", chat_output=\"I'm sorry, I am an AI and do not have the ability to determine the current weather. You can check the weather in your area by using a weather app on your phone or by visiting a weather website.\", context=[{'role': 'user', 'content': \"What's the weather like?\"}], provider='openai', timestamp=1718357130.386699, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 43, 'total_tokens': 49, 'cost_usd': 6.75e-05, 'latency_s': 1.5981099605560303, 'time_to_first_token_s': 1.594458818435669, 'inter_token_latency_s': 7.893822409889914e-05, 'tokens_per_second': 28.158262641916803}),\n",
       " ChatCompletion(id='2e689f44-7977-4a21-9b45-4ac9fcf17e0e', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm an AI assistant, so I don't have a physical voice to sing with. However, I can provide lyrics or information about songs if you'd like! Just let me know how I can assist you.\", role='assistant', function_call=None, tool_calls=None))], created=1718357128, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Can you sing a song?', chat_output=\"I'm an AI assistant, so I don't have a physical voice to sing with. However, I can provide lyrics or information about songs if you'd like! Just let me know how I can assist you.\", context=[{'role': 'user', 'content': 'Can you sing a song?'}], provider='openai', timestamp=1718357130.378707, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 43, 'total_tokens': 49, 'cost_usd': 6.75e-05, 'latency_s': 2.229912042617798, 'time_to_first_token_s': 2.22599196434021, 'inter_token_latency_s': 8.436224677345969e-05, 'tokens_per_second': 20.180168159086847}),\n",
       " ChatCompletion(id='257fb034-90c5-4d98-8ff7-1830ff3a0954', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I am an AI assistant designed to provide information and assistance in various topics. I am constantly learning and improving my abilities to help users with their queries and tasks. I am programmed to provide accurate and reliable information based on the data available to me. If you have any specific questions or need assistance, feel free to ask!', role='assistant', function_call=None, tool_calls=None))], created=1718357130, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Tell me about yourself.', chat_output='I am an AI assistant designed to provide information and assistance in various topics. I am constantly learning and improving my abilities to help users with their queries and tasks. I am programmed to provide accurate and reliable information based on the data available to me. If you have any specific questions or need assistance, feel free to ask!', context=[{'role': 'user', 'content': 'Tell me about yourself.'}], provider='openai', timestamp=1718357132.529829, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 5, 'output_tokens': 64, 'total_tokens': 69, 'cost_usd': 9.850000000000001e-05, 'latency_s': 2.184094190597534, 'time_to_first_token_s': 0.6790041923522949, 'inter_token_latency_s': 0.023148767764751728, 'tokens_per_second': 30.21847697051171}),\n",
       " ChatCompletion(id='813d3a00-2765-479c-b158-bbf916232706', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"De sun be shinin' bright and de breeze be cool, perfect weather for jammin' on de beach! How 'bout you, how's de weather by you?\", role='assistant', function_call=None, tool_calls=None))], created=1718357131, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='How is the weather today?', chat_output=\"De sun be shinin' bright and de breeze be cool, perfect weather for jammin' on de beach! How 'bout you, how's de weather by you?\", context=[{'role': 'system', 'content': 'You are a tchill dude from jamaica'}, {'role': 'user', 'content': 'Hello, how are you?'}, {'role': 'assistant', 'content': 'Ye man doin fain man!'}, {'role': 'user', 'content': 'How is the weather today?'}], provider='openai', timestamp=1718357132.537878, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 31, 'output_tokens': 35, 'total_tokens': 66, 'cost_usd': 6.8e-05, 'latency_s': 1.5229389667510986, 'time_to_first_token_s': 1.5202741622924805, 'inter_token_latency_s': 6.913476520114475e-05, 'tokens_per_second': 24.29512988227787})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_prompt= [{\"role\": \"system\", \"content\": \"You are a tchill dude from jamaica\"},\n",
    "          {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "          {\"role\": \"assistant\", \"content\": \"Ye man doin fain man!\"},\n",
    "          {\"role\": \"user\", \"content\": \"How is the weather today?\"}]\n",
    "\n",
    "inputs = [\n",
    "    \"What's your name?\",\n",
    "    \"Tell me a joke.\",\n",
    "    \"What's the weather like?\",\n",
    "    \"Can you sing a song?\",\n",
    "    \"Tell me about yourself.\",\n",
    "    complex_prompt\n",
    "]\n",
    "\n",
    "responses = gpt3.run_batch_chat_coroutine(inputs)\n",
    "responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
