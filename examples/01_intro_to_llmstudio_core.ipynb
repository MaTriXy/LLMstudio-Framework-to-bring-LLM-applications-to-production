{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LLMstudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio_core import LLMCore as LLM\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set OPENAI_API_KEY and ANTHROPIC_API_KEY on .env file\n",
    "\n",
    "# anthropic = LLM(\"anthropic\") # or you can pass api_key as an argument here\n",
    "openai = LLM(\"openai\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='e67fd10c-e2d4-442d-9140-1d73d5345e78', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I’m OpenAI’s language model, and I don’t have a personal name, but you can call me Assistant! How can I help you today?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729091027, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output='I’m OpenAI’s language model, and I don’t have a personal name, but you can call me Assistant! How can I help you today?', chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729091027.668681, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 31, 'total_tokens': 35, 'cost_usd': 0.000485, 'latency_s': 0.9814362525939941, 'time_to_first_token_s': 0.5442612171173096, 'inter_token_latency_s': 0.013376839458942413, 'tokens_per_second': 33.624190988236926})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.chat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='2abb7143-6fec-453f-a088-8e68bd024450', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I don't have a personal name, but you can call me Assistant. How can I help you today?\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729091028, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output=\"I don't have a personal name, but you can call me Assistant. How can I help you today?\", chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729091028.540685, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 22, 'total_tokens': 26, 'cost_usd': 0.00035, 'latency_s': 0.8616046905517578, 'time_to_first_token_s': 0.48931884765625, 'inter_token_latency_s': 0.01686550270427357, 'tokens_per_second': 26.6943764956423})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await openai.achat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, the final frontier, is an awe-inspiring expanse that has captivated human imagination for\n",
      "\n",
      " centuries. It is a vast, seemingly infinite realm filled with wonders beyond our full comprehension, from radiant\n",
      "\n",
      " stars and swirling galaxies to mysterious black holes and distant, perhaps habitable, planets. Space is not\n",
      "\n",
      " merely the absence of earthly bounds but a vast, dynamic tapestry woven with the delicate interplay of gravity,\n",
      "\n",
      " time, and matter. The exploration of space presents unparalleled opportunities for scientific discovery, technological advancement, and\n",
      "\n",
      " a deeper understanding of our place in the universe. As we venture further into the cosmos, peering\n",
      "\n",
      " through sophisticated telescopes and embarking on ambitious missions, space continues to challenge our intellect, inspiring a profound\n",
      "\n",
      " sense of curiosity and a relentless pursuit of knowledge — inviting us to explore its boundless possibilities and seek\n",
      "\n",
      " answers to some of humanity's most fundamental questions.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.002635,\n",
      " 'input_tokens': 8,\n",
      " 'inter_token_latency_s': 0.009682952656465418,\n",
      " 'latency_s': 2.4021809101104736,\n",
      " 'output_tokens': 173,\n",
      " 'time_to_first_token_s': 0.7550098896026611,\n",
      " 'tokens_per_second': 71.18531301297199,\n",
      " 'total_tokens': 181}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"Write a paragfraph about space\", model=\"gpt-4o\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if chunk.chat_output_stream:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    elif chunk.metrics:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hi there! How can I assist you today?\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 6.45e-06,\n",
      " 'input_tokens': 3,\n",
      " 'inter_token_latency_s': 0.02283191680908203,\n",
      " 'latency_s': 1.0239500999450684,\n",
      " 'output_tokens': 10,\n",
      " 'time_to_first_token_s': 0.7725250720977783,\n",
      " 'tokens_per_second': 11.719321088638754,\n",
      " 'total_tokens': 13}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "i=0\n",
    "async for chunk in await openai.achat(\"Say hi back\", model=\"gpt-4o-mini\", is_stream=True):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if chunk.chat_output_stream:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    elif chunk.metrics:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
