{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LLMstudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio_core.providers import LLMCore as LLM\n",
    "from pprint import pprint\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set OPENAI_API_KEY environment variable, add it to .env, or pass directly as api_key\n",
    "openai = LLM(\"openai\", api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "from llmstudio_core.providers import LLMCore as LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='c6258dcf-4663-4872-b8d9-dd4155bacaec', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I’m an AI created by OpenAI with no personal name, but you can call me Assistant or any name you prefer! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729521189, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output='I’m an AI created by OpenAI with no personal name, but you can call me Assistant or any name you prefer! How can I assist you today?', chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729521191.590282, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 32, 'total_tokens': 36, 'cost_usd': 0.0005, 'latency_s': 2.0628280639648438, 'time_to_first_token_s': 0.6581661701202393, 'inter_token_latency_s': 0.042202667756514115, 'tokens_per_second': 16.482226800158298})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.chat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='ed7ca418-2e6c-408f-8285-7347c769d788', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I’m an AI language model created by OpenAI, and I don’t have a personal name. You can call me whatever you like!', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729521191, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output='I’m an AI language model created by OpenAI, and I don’t have a personal name. You can call me whatever you like!', chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729521192.389187, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 28, 'total_tokens': 32, 'cost_usd': 0.00044, 'latency_s': 0.7901167869567871, 'time_to_first_token_s': 0.46891283988952637, 'inter_token_latency_s': 0.011061347764113853, 'tokens_per_second': 37.96907051620554})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await openai.achat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space is an awe-inspiring expanse that stretches beyond the confines of our planet, offering endless\n",
      "\n",
      " possibilities for exploration and discovery. It is a vast and largely uncharted frontier, home to billions of\n",
      "\n",
      " galaxies, stars, and planets, each with its own unique set of characteristics and phenomena. The study\n",
      "\n",
      " of space not only fuels our curiosity about the universe and our place within it but also drives technological advancements\n",
      "\n",
      " and fosters international collaboration. As humans venture further into this final frontier, missions to the Moon, Mars\n",
      "\n",
      ", and beyond continue to push the boundaries of what is possible, unveiling the mysteries of cosmic phenomena and\n",
      "\n",
      " potentially uncovering signs of extraterrestrial life. Amidst the cosmic wonders, space also serves as a\n",
      "\n",
      " poignant reminder of Earth's fragility, highlighting the need for global cooperation to preserve our planet for future generations\n",
      "\n",
      ".\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.00247,\n",
      " 'input_tokens': 5,\n",
      " 'inter_token_latency_s': 0.03068469622120354,\n",
      " 'latency_s': 5.3832011222839355,\n",
      " 'output_tokens': 163,\n",
      " 'time_to_first_token_s': 0.4419829845428467,\n",
      " 'tokens_per_second': 30.093618336011215,\n",
      " 'total_tokens': 168}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"Write a paragraph about space\", model=\"gpt-4o\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if chunk.chat_output_stream:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    elif chunk.metrics:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hi! How can I help you today?\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 5.85e-06,\n",
      " 'input_tokens': 3,\n",
      " 'inter_token_latency_s': 0.012278413772583008,\n",
      " 'latency_s': 0.8510980606079102,\n",
      " 'output_tokens': 9,\n",
      " 'time_to_first_token_s': 0.726921796798706,\n",
      " 'tokens_per_second': 12.924480161713772,\n",
      " 'total_tokens': 12}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "async for chunk in await openai.achat(\"Say hi back\", model=\"gpt-4o-mini\", is_stream=True):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if chunk.chat_output_stream:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    elif chunk.metrics:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(provider=\"azure\", \n",
    "          api_key=os.environ[\"AZURE_API_KEY\"], \n",
    "          api_version=os.environ[\"AZURE_API_VERSION\"],\n",
    "          api_endpoint=os.environ[\"AZURE_API_ENDPOINT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I'm an AI developed by OpenAI, and I don't have a personal name. You can just call me Assistant! How can I assist you today?\",\n",
       " {'input_tokens': 4,\n",
       "  'output_tokens': 32,\n",
       "  'total_tokens': 36,\n",
       "  'cost_usd': 0.0005,\n",
       "  'latency_s': 1.279374122619629,\n",
       "  'time_to_first_token_s': 0.6514542102813721,\n",
       "  'inter_token_latency_s': 0.016437930445517262,\n",
       "  'tokens_per_second': 25.012230147720388},\n",
       " 'gpt-4o-2024-05-13')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.chat(\"What's your name\", model=\"gpt-4o\")\n",
    "response.chat_output, response.metrics, response.deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I don't have a personal name, but you can call me Assistant. How can I help you today?\",\n",
       " {'input_tokens': 4,\n",
       "  'output_tokens': 22,\n",
       "  'total_tokens': 26,\n",
       "  'cost_usd': 0.00035,\n",
       "  'latency_s': 0.8751637935638428,\n",
       "  'time_to_first_token_s': 0.2761850357055664,\n",
       "  'inter_token_latency_s': 0.02181818268515847,\n",
       "  'tokens_per_second': 26.28079471425501},\n",
       " 'gpt-4o-2024-05-13')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await llm.achat(\"What's your name\", model=\"gpt-4o\")\n",
    "response.chat_output, response.metrics, response.deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
