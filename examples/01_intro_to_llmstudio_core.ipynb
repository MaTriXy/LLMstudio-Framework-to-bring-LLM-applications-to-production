{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LLMstudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set OPENAI_API_KEY environment variable, add it to .env, or pass directly as api_key\n",
    "from llmstudio_core.providers import LLMCore as LLM\n",
    "openai = LLM(\"openai\", api_key=os.environ[\"OPENAI_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='cd37ddf2-240f-4284-b487-b60a178402b5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m an AI language model created by OpenAI, and I don\\'t have a personal name. You can just call me \"Assistant.\" How can I help you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729535990, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output='I\\'m an AI language model created by OpenAI, and I don\\'t have a personal name. You can just call me \"Assistant.\" How can I help you today?', chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729535990.5355158, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 35, 'total_tokens': 39, 'cost_usd': 0.000545, 'latency_s': 0.9189841747283936, 'time_to_first_token_s': 0.5386989116668701, 'inter_token_latency_s': 0.011158031575820026, 'tokens_per_second': 38.08553070061764})\n",
      "(\"I'm an AI language model created by OpenAI, and I don't have a personal \"\n",
      " 'name. You can just call me \"Assistant.\" How can I help you today?')\n",
      "{'cost_usd': 0.000545,\n",
      " 'input_tokens': 4,\n",
      " 'inter_token_latency_s': 0.011158031575820026,\n",
      " 'latency_s': 0.9189841747283936,\n",
      " 'output_tokens': 35,\n",
      " 'time_to_first_token_s': 0.5386989116668701,\n",
      " 'tokens_per_second': 38.08553070061764,\n",
      " 'total_tokens': 39}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"What's your name\", model=\"gpt-4o\")\n",
    "print(response)\n",
    "print(response.chat_output)\n",
    "pprint(response.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='c57d2ebd-251a-441d-8e80-844ab9900c49', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I’m called Assistant. What's your name?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729536006, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output=\"I’m called Assistant. What's your name?\", chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729536007.162428, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 10, 'total_tokens': 14, 'cost_usd': 0.00017, 'latency_s': 0.6478960514068604, 'time_to_first_token_s': 0.4633328914642334, 'inter_token_latency_s': 0.018413186073303223, 'tokens_per_second': 16.978032164441007})\n",
      "\"I’m called Assistant. What's your name?\"\n",
      "{'cost_usd': 0.00017,\n",
      " 'input_tokens': 4,\n",
      " 'inter_token_latency_s': 0.018413186073303223,\n",
      " 'latency_s': 0.6478960514068604,\n",
      " 'output_tokens': 10,\n",
      " 'time_to_first_token_s': 0.4633328914642334,\n",
      " 'tokens_per_second': 16.978032164441007,\n",
      " 'total_tokens': 14}\n"
     ]
    }
   ],
   "source": [
    "response = await openai.achat(\"What's your name\", model=\"gpt-4o\")\n",
    "print(response)\n",
    "print(response.chat_output)\n",
    "pprint(response.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space is a vast and enigmatic expanse that stretches beyond the confines of our solar system, encompassing\n",
      "\n",
      " galaxies, stars, planets, and celestial phenomena. It is a realm where the laws of physics as\n",
      "\n",
      " we know them are tested to their limits, offering both challenges and opportunities for discovery. Our fascination with\n",
      "\n",
      " space has driven technological advancements and fostered curiosity about the origins of the universe and the possibility of extrater\n",
      "\n",
      "restrial life. Despite the harsh and inhospitable conditions found in space, humanity continues to explore its\n",
      "\n",
      " depths through innovative missions and spacecraft, seeking to unravel the mysteries of dark matter, black holes, and\n",
      "\n",
      " the vast cosmic web that binds the universe. From the inspiring imagery of distant nebulas to the pursuit\n",
      "\n",
      " of knowledge in astrophysics, space remains a frontier that captivates the imagination and fuels the quest for\n",
      "\n",
      " understanding our place in the cosmos.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.002605,\n",
      " 'input_tokens': 5,\n",
      " 'inter_token_latency_s': 0.007976327827590668,\n",
      " 'latency_s': 2.6310627460479736,\n",
      " 'output_tokens': 172,\n",
      " 'time_to_first_token_s': 1.2983660697937012,\n",
      " 'tokens_per_second': 63.85252508795043,\n",
      " 'total_tokens': 177}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"Write a paragraph about space\", model=\"gpt-4o\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if chunk.chat_output_stream:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    elif chunk.metrics:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hi there! How can I assist you today?\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 6.45e-06,\n",
      " 'input_tokens': 3,\n",
      " 'inter_token_latency_s': 0.015123107216574928,\n",
      " 'latency_s': 1.0157017707824707,\n",
      " 'output_tokens': 10,\n",
      " 'time_to_first_token_s': 0.8489949703216553,\n",
      " 'tokens_per_second': 11.814491561588502,\n",
      " 'total_tokens': 13}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "async for chunk in await openai.achat(\"Say hi back\", model=\"gpt-4o-mini\", is_stream=True):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if chunk.chat_output_stream:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    elif chunk.metrics:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(provider=\"azure\", \n",
    "          api_key=os.environ[\"AZURE_API_KEY\"], \n",
    "          api_version=os.environ[\"AZURE_API_VERSION\"],\n",
    "          api_endpoint=os.environ[\"AZURE_API_ENDPOINT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='ab0d7f9d-b510-4a3d-9fa5-018f61a30935', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm an AI developed by OpenAI, and I don't have a personal name. However, you can call me Assistant. How can I help you today?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729536154, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output=\"I'm an AI developed by OpenAI, and I don't have a personal name. However, you can call me Assistant. How can I help you today?\", chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='azure', deployment='gpt-4o-2024-05-13', timestamp=1729536154.9160051, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 33, 'total_tokens': 37, 'cost_usd': 0.000515, 'latency_s': 1.329728126525879, 'time_to_first_token_s': 0.7403469085693359, 'inter_token_latency_s': 0.014576815068721771, 'tokens_per_second': 24.817103091755772})\n",
      "I'm an AI developed by OpenAI, and I don't have a personal name. However, you can call me Assistant. How can I help you today?\n",
      "{'cost_usd': 0.000515,\n",
      " 'input_tokens': 4,\n",
      " 'inter_token_latency_s': 0.014576815068721771,\n",
      " 'latency_s': 1.329728126525879,\n",
      " 'output_tokens': 33,\n",
      " 'time_to_first_token_s': 0.7403469085693359,\n",
      " 'tokens_per_second': 24.817103091755772,\n",
      " 'total_tokens': 37}\n"
     ]
    }
   ],
   "source": [
    "response = llm.chat(\"What's your name\", model=\"gpt-4o\")\n",
    "print(response)\n",
    "print(response.chat_output)\n",
    "pprint(response.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='0a9dadd5-ec23-4cc0-b4bc-f6f6e5786e0d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm an AI developed by OpenAI, often referred to as ChatGPT. I don't have a personal name, but you can call me whatever you'd like! How can I assist you today?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729536066, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output=\"I'm an AI developed by OpenAI, often referred to as ChatGPT. I don't have a personal name, but you can call me whatever you'd like! How can I assist you today?\", chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='azure', deployment='gpt-4o-2024-05-13', timestamp=1729536067.184789, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 42, 'total_tokens': 46, 'cost_usd': 0.0006500000000000001, 'latency_s': 1.3636717796325684, 'time_to_first_token_s': 0.7343719005584717, 'inter_token_latency_s': 0.013125309577355018, 'tokens_per_second': 29.332571515689587})\n",
      "I'm an AI developed by OpenAI, often referred to as ChatGPT. I don't have a personal name, but you can call me whatever you'd like! How can I assist you today?\n",
      "{'cost_usd': 0.0006500000000000001,\n",
      " 'input_tokens': 4,\n",
      " 'inter_token_latency_s': 0.013125309577355018,\n",
      " 'latency_s': 1.3636717796325684,\n",
      " 'output_tokens': 42,\n",
      " 'time_to_first_token_s': 0.7343719005584717,\n",
      " 'tokens_per_second': 29.332571515689587,\n",
      " 'total_tokens': 46}\n"
     ]
    }
   ],
   "source": [
    "response = await llm.achat(\"What's your name\", model=\"gpt-4o\")\n",
    "print(response)\n",
    "print(response.chat_output)\n",
    "pprint(response.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
