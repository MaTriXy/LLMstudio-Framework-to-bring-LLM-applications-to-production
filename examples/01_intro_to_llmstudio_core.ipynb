{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LLMstudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio_core.providers import LLMCore as LLM\n",
    "from pprint import pprint\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set OPENAI_API_KEY environment variable, add it to .env, or pass directly as api_key\n",
    "openai = LLM(\"openai\", api_key=os.environ[\"OPENAI_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='3230afeb-9df3-463a-9157-5e3b2e92a00d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm an AI language model created by OpenAI, and I don't have a personal name, but you can call me Assistant if you'd like! How can I help you today?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729516558, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output=\"I'm an AI language model created by OpenAI, and I don't have a personal name, but you can call me Assistant if you'd like! How can I help you today?\", chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729516558.998754, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 38, 'total_tokens': 42, 'cost_usd': 0.00059, 'latency_s': 1.1465322971343994, 'time_to_first_token_s': 0.58030104637146, 'inter_token_latency_s': 0.01533108287387424, 'tokens_per_second': 32.271223490586735})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.chat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='c22be7d5-1c17-48d7-b4d5-f16410aeb864', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I’m an AI language model created by OpenAI, and I don’t have a personal name. You can just call me Assistant! How can I help you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729516559, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, chat_input=\"What's your name\", chat_output='I’m an AI language model created by OpenAI, and I don’t have a personal name. You can just call me Assistant! How can I help you today?', chat_output_stream='', context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4o-2024-08-06', timestamp=1729516559.822921, parameters={}, metrics={'input_tokens': 4, 'output_tokens': 34, 'total_tokens': 38, 'cost_usd': 0.0005300000000000001, 'latency_s': 0.8132920265197754, 'time_to_first_token_s': 0.34262919425964355, 'inter_token_latency_s': 0.013441344669886997, 'tokens_per_second': 44.2645431482349})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await openai.achat(\"What's your name\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Space, the vast and seemingly infinite expanse that stretches beyond the confines of our planet, has\n",
      "\n",
      " captivated human imagination for centuries. It is a realm filled with countless wonders and mysteries, from the blazing\n",
      "\n",
      " stars scattered across the night sky to the enigmatic black holes that challenge our understanding of physics. Space exploration\n",
      "\n",
      " has become a testament to human ingenuity and curiosity, with missions reaching far-off planets, moons, and\n",
      "\n",
      " even asteroids. The advancement of space technology promises not only to deepen our comprehension of the universe but\n",
      "\n",
      " also to potentially secure the future of humanity through discoveries of new resources and habitats. As we peer into\n",
      "\n",
      " the cosmos, we are reminded of our place in the universe and the intricate web of celestial bodies that\n",
      "\n",
      " surround us, inspiring dreams of new frontiers and the quest for knowledge that knows no bounds.\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 0.002425,\n",
      " 'input_tokens': 5,\n",
      " 'inter_token_latency_s': 0.016525716901575244,\n",
      " 'latency_s': 3.16186785697937,\n",
      " 'output_tokens': 160,\n",
      " 'time_to_first_token_s': 0.533703088760376,\n",
      " 'tokens_per_second': 50.60300026353819,\n",
      " 'total_tokens': 165}\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat(\"Write a paragraph about space\", model=\"gpt-4o\", is_stream=True)\n",
    "for i, chunk in enumerate(response):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if chunk.chat_output_stream:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    elif chunk.metrics:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hi there! How can I assist you today?\n",
      "\n",
      "## Metrics:\n",
      "{'cost_usd': 6.45e-06,\n",
      " 'input_tokens': 3,\n",
      " 'inter_token_latency_s': 0.018438447605479847,\n",
      " 'latency_s': 0.7882611751556396,\n",
      " 'output_tokens': 10,\n",
      " 'time_to_first_token_s': 0.5848991870880127,\n",
      " 'tokens_per_second': 15.223380750207111,\n",
      " 'total_tokens': 13}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "async for chunk in await openai.achat(\"Say hi back\", model=\"gpt-4o-mini\", is_stream=True):\n",
    "    if i%20==0:\n",
    "        print(\"\\n\")\n",
    "    if chunk.chat_output_stream:\n",
    "        print(chunk.chat_output_stream, end=\"\", flush=True)\n",
    "    elif chunk.metrics:\n",
    "        print(\"\\n\\n## Metrics:\")\n",
    "        pprint(chunk.metrics)\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
